{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, cross_val_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../../data/exosomes.raw_spectrum_1.csv\")\n",
    "#df = pd.read_csv(\"../../data/exosomes.raw_spectrum_380-1800.csv\")\n",
    "#df = pd.read_csv(\"../../data/exosomes.raw_spectrum_400-1800.csv\")\n",
    "df = pd.read_csv(\"../../data/current_clean_spectrum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>WaveNumber</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Absorbance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>293</td>\n",
       "      <td>400.22778</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.863303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>294</td>\n",
       "      <td>400.91116</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.803843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>295</td>\n",
       "      <td>401.59454</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.741884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>296</td>\n",
       "      <td>402.27789</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.677722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>297</td>\n",
       "      <td>402.96127</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.611654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239200</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2337</td>\n",
       "      <td>1797.03870</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>12.378163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239201</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2338</td>\n",
       "      <td>1797.72200</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>13.269937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239202</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2339</td>\n",
       "      <td>1798.40550</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>14.199285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239203</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2340</td>\n",
       "      <td>1799.08890</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>15.166531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239204</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2341</td>\n",
       "      <td>1799.77220</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>16.171997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6239205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SpecID   Seq  WaveNumber     SurID         Status  Absorbance\n",
       "0        201210-1-00   293   400.22778  201210-1         Normal   41.863303\n",
       "1        201210-1-00   294   400.91116  201210-1         Normal   41.803843\n",
       "2        201210-1-00   295   401.59454  201210-1         Normal   41.741884\n",
       "3        201210-1-00   296   402.27789  201210-1         Normal   41.677722\n",
       "4        201210-1-00   297   402.96127  201210-1         Normal   41.611654\n",
       "...              ...   ...         ...       ...            ...         ...\n",
       "6239200  210526-3-09  2337  1797.03870  210526-3  Hyperglycemia   12.378163\n",
       "6239201  210526-3-09  2338  1797.72200  210526-3  Hyperglycemia   13.269937\n",
       "6239202  210526-3-09  2339  1798.40550  210526-3  Hyperglycemia   14.199285\n",
       "6239203  210526-3-09  2340  1799.08890  210526-3  Hyperglycemia   15.166531\n",
       "6239204  210526-3-09  2341  1799.77220  210526-3  Hyperglycemia   16.171997\n",
       "\n",
       "[6239205 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wavelength_df(df, absorbance_col, status_col='Status'):\n",
    "\n",
    "    # Pivot the DataFrame to get wavelengths as columns and absorbance values\n",
    "    wavelength_df = df.pivot(index='SpecID', columns='WaveNumber', values=absorbance_col).reset_index()\n",
    "    wavelength_df.columns.name = None\n",
    "\n",
    "    # Merge with the statuses based on SpecID\n",
    "    # Include the SurID to perform GroupKFold CV\n",
    "    statuses_and_surface = df[['SpecID', 'SurID', status_col]].drop_duplicates()\n",
    "    wavelength_df = pd.merge(wavelength_df, statuses_and_surface, on='SpecID')\n",
    "\n",
    "    # Set SpecID as the index\n",
    "    wavelength_df = wavelength_df.set_index('SpecID')\n",
    "\n",
    "    return wavelength_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees(df):\n",
    "\n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy',groups=groups)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_df = prepare_wavelength_df(df, 'Absorbance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>400.22778</th>\n",
       "      <th>400.91116</th>\n",
       "      <th>401.59454</th>\n",
       "      <th>402.27789</th>\n",
       "      <th>402.96127</th>\n",
       "      <th>403.64465</th>\n",
       "      <th>404.32803</th>\n",
       "      <th>405.01138</th>\n",
       "      <th>405.69476</th>\n",
       "      <th>406.37814</th>\n",
       "      <th>...</th>\n",
       "      <th>1794.9886</th>\n",
       "      <th>1795.672</th>\n",
       "      <th>1796.3553</th>\n",
       "      <th>1797.0387</th>\n",
       "      <th>1797.722</th>\n",
       "      <th>1798.4055</th>\n",
       "      <th>1799.0889</th>\n",
       "      <th>1799.7722</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>41.863303</td>\n",
       "      <td>41.803843</td>\n",
       "      <td>41.741884</td>\n",
       "      <td>41.677722</td>\n",
       "      <td>41.611654</td>\n",
       "      <td>41.543974</td>\n",
       "      <td>41.474980</td>\n",
       "      <td>41.404968</td>\n",
       "      <td>41.334234</td>\n",
       "      <td>41.263073</td>\n",
       "      <td>...</td>\n",
       "      <td>6.280946</td>\n",
       "      <td>5.549559</td>\n",
       "      <td>4.745724</td>\n",
       "      <td>3.866578</td>\n",
       "      <td>2.909255</td>\n",
       "      <td>1.870891</td>\n",
       "      <td>0.748623</td>\n",
       "      <td>-0.460415</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>46.314608</td>\n",
       "      <td>47.323684</td>\n",
       "      <td>48.299209</td>\n",
       "      <td>49.241395</td>\n",
       "      <td>50.150457</td>\n",
       "      <td>51.026608</td>\n",
       "      <td>51.870063</td>\n",
       "      <td>52.681035</td>\n",
       "      <td>53.459738</td>\n",
       "      <td>54.206386</td>\n",
       "      <td>...</td>\n",
       "      <td>6.769011</td>\n",
       "      <td>7.280928</td>\n",
       "      <td>7.861246</td>\n",
       "      <td>8.512936</td>\n",
       "      <td>9.238972</td>\n",
       "      <td>10.042323</td>\n",
       "      <td>10.925962</td>\n",
       "      <td>11.892860</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>118.159018</td>\n",
       "      <td>114.686240</td>\n",
       "      <td>111.563911</td>\n",
       "      <td>108.777452</td>\n",
       "      <td>106.312282</td>\n",
       "      <td>104.153823</td>\n",
       "      <td>102.287493</td>\n",
       "      <td>100.698715</td>\n",
       "      <td>99.372907</td>\n",
       "      <td>98.295491</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.633601</td>\n",
       "      <td>-4.557349</td>\n",
       "      <td>-4.439365</td>\n",
       "      <td>-4.278894</td>\n",
       "      <td>-4.075180</td>\n",
       "      <td>-3.827470</td>\n",
       "      <td>-3.535010</td>\n",
       "      <td>-3.197043</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>175.466997</td>\n",
       "      <td>174.846086</td>\n",
       "      <td>174.188020</td>\n",
       "      <td>173.498226</td>\n",
       "      <td>172.782129</td>\n",
       "      <td>172.045155</td>\n",
       "      <td>171.292728</td>\n",
       "      <td>170.530275</td>\n",
       "      <td>169.763222</td>\n",
       "      <td>168.996993</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.801936</td>\n",
       "      <td>-10.349539</td>\n",
       "      <td>-9.864191</td>\n",
       "      <td>-9.347124</td>\n",
       "      <td>-8.799567</td>\n",
       "      <td>-8.222752</td>\n",
       "      <td>-7.617909</td>\n",
       "      <td>-6.986269</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>111.814973</td>\n",
       "      <td>106.629998</td>\n",
       "      <td>101.867380</td>\n",
       "      <td>97.512673</td>\n",
       "      <td>93.551430</td>\n",
       "      <td>89.969205</td>\n",
       "      <td>86.751551</td>\n",
       "      <td>83.884023</td>\n",
       "      <td>81.352173</td>\n",
       "      <td>79.141556</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.689508</td>\n",
       "      <td>-11.752441</td>\n",
       "      <td>-11.789205</td>\n",
       "      <td>-11.799583</td>\n",
       "      <td>-11.783357</td>\n",
       "      <td>-11.740310</td>\n",
       "      <td>-11.670224</td>\n",
       "      <td>-11.572882</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              400.22778   400.91116   401.59454   402.27789   402.96127  \\\n",
       "SpecID                                                                    \n",
       "201210-1-00   41.863303   41.803843   41.741884   41.677722   41.611654   \n",
       "201210-1-01   46.314608   47.323684   48.299209   49.241395   50.150457   \n",
       "201210-1-02  118.159018  114.686240  111.563911  108.777452  106.312282   \n",
       "201210-1-03  175.466997  174.846086  174.188020  173.498226  172.782129   \n",
       "201210-1-04  111.814973  106.629998  101.867380   97.512673   93.551430   \n",
       "\n",
       "              403.64465   404.32803   405.01138   405.69476   406.37814  ...  \\\n",
       "SpecID                                                                   ...   \n",
       "201210-1-00   41.543974   41.474980   41.404968   41.334234   41.263073  ...   \n",
       "201210-1-01   51.026608   51.870063   52.681035   53.459738   54.206386  ...   \n",
       "201210-1-02  104.153823  102.287493  100.698715   99.372907   98.295491  ...   \n",
       "201210-1-03  172.045155  171.292728  170.530275  169.763222  168.996993  ...   \n",
       "201210-1-04   89.969205   86.751551   83.884023   81.352173   79.141556  ...   \n",
       "\n",
       "             1794.9886   1795.672  1796.3553  1797.0387   1797.722  1798.4055  \\\n",
       "SpecID                                                                          \n",
       "201210-1-00   6.280946   5.549559   4.745724   3.866578   2.909255   1.870891   \n",
       "201210-1-01   6.769011   7.280928   7.861246   8.512936   9.238972  10.042323   \n",
       "201210-1-02  -4.633601  -4.557349  -4.439365  -4.278894  -4.075180  -3.827470   \n",
       "201210-1-03 -10.801936 -10.349539  -9.864191  -9.347124  -8.799567  -8.222752   \n",
       "201210-1-04 -11.689508 -11.752441 -11.789205 -11.799583 -11.783357 -11.740310   \n",
       "\n",
       "             1799.0889  1799.7722     SurID  Status  \n",
       "SpecID                                               \n",
       "201210-1-00   0.748623  -0.460415  201210-1  Normal  \n",
       "201210-1-01  10.925962  11.892860  201210-1  Normal  \n",
       "201210-1-02  -3.535010  -3.197043  201210-1  Normal  \n",
       "201210-1-03  -7.617909  -6.986269  201210-1  Normal  \n",
       "201210-1-04 -11.670224 -11.572882  201210-1  Normal  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees(df):\n",
    "\n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy',groups=groups, n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.6123 +/- 0.1083\n"
     ]
    }
   ],
   "source": [
    "evaluate_extra_trees(wavelength_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Greedy Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_feature_selection(df):\n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "\n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "\n",
    "    # Feature selector\n",
    "    sfs = SequentialFeatureSelector(et,\n",
    "                                    k_features=(1, 50),\n",
    "                                     forward=True,\n",
    "                                     scoring='accuracy',\n",
    "                                     cv=cv,\n",
    "                                     n_jobs=-1,\n",
    "                                     verbose=2)\n",
    "\n",
    "    # Fit the feature selector\n",
    "    sfs = sfs.fit(X, y, groups=groups)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_feature_names = list(X.columns[list(sfs.k_feature_idx_)])\n",
    "\n",
    "    # Create a DataFrame with selected features\n",
    "    selected_features_df = pd.DataFrame(selected_feature_names, columns=['Selected Features'])\n",
    "\n",
    "    # Getting cross-validation scores with selected features\n",
    "    scores = cross_val_score(et, X[selected_feature_names], y, cv=cv, scoring='accuracy', groups=groups)\n",
    "\n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy with feature selection: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')\n",
    "\n",
    "    # Return the DataFrame with selected features\n",
    "    return selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2049 out of 2049 | elapsed: 10.5min finished\n",
      "\n",
      "[2024-04-10 00:55:19] Features: 1/50 -- score: 0.4067936507936508[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2048 out of 2048 | elapsed: 10.0min finished\n",
      "\n",
      "[2024-04-10 01:05:18] Features: 2/50 -- score: 0.49919047619047613[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2047 out of 2047 | elapsed:  9.6min finished\n",
      "\n",
      "[2024-04-10 01:14:55] Features: 3/50 -- score: 0.5407460317460318[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2046 out of 2046 | elapsed: 10.6min finished\n",
      "\n",
      "[2024-04-10 01:25:31] Features: 4/50 -- score: 0.5762222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2045 out of 2045 | elapsed: 10.6min finished\n",
      "\n",
      "[2024-04-10 01:36:10] Features: 5/50 -- score: 0.5994444444444446[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.7min\n"
     ]
    }
   ],
   "source": [
    "selected_features = greedy_feature_selection(wavelength_df)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.to_csv(\"../../data/et_greedy_search.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SequentialFeatureSelector in module mlxtend.feature_selection.sequential_feature_selector:\n",
      "\n",
      "class SequentialFeatureSelector(mlxtend.utils.base_compostion._BaseXComposition, sklearn.base.MetaEstimatorMixin)\n",
      " |  SequentialFeatureSelector(estimator, k_features=1, forward=True, floating=False, verbose=0, scoring=None, cv=5, n_jobs=1, pre_dispatch='2*n_jobs', clone_estimator=True, fixed_features=None, feature_groups=None)\n",
      " |  \n",
      " |  Sequential Feature Selection for Classification and Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : scikit-learn classifier or regressor\n",
      " |  k_features : int or tuple or str (default: 1)\n",
      " |      Number of features to select,\n",
      " |      where k_features < the full feature set.\n",
      " |      New in 0.4.2: A tuple containing a min and max value can be provided,\n",
      " |          and the SFS will consider return any feature combination between\n",
      " |          min and max that scored highest in cross-validation. For example,\n",
      " |          the tuple (1, 4) will return any combination from\n",
      " |          1 up to 4 features instead of a fixed number of features k.\n",
      " |      New in 0.8.0: A string argument \"best\" or \"parsimonious\".\n",
      " |          If \"best\" is provided, the feature selector will return the\n",
      " |          feature subset with the best cross-validation performance.\n",
      " |          If \"parsimonious\" is provided as an argument, the smallest\n",
      " |          feature subset that is within one standard error of the\n",
      " |          cross-validation performance will be selected.\n",
      " |  \n",
      " |  forward : bool (default: True)\n",
      " |      Forward selection if True,\n",
      " |      backward selection otherwise\n",
      " |  \n",
      " |  floating : bool (default: False)\n",
      " |      Adds a conditional exclusion/inclusion if True.\n",
      " |  \n",
      " |  verbose : int (default: 0), level of verbosity to use in logging.\n",
      " |      If 0, no output,\n",
      " |      if 1 number of features in current set, if 2 detailed logging i\n",
      " |      ncluding timestamp and cv scores at step.\n",
      " |  \n",
      " |  scoring : str, callable, or None (default: None)\n",
      " |      If None (default), uses 'accuracy' for sklearn classifiers\n",
      " |      and 'r2' for sklearn regressors.\n",
      " |      If str, uses a sklearn scoring metric string identifier, for example\n",
      " |      {accuracy, f1, precision, recall, roc_auc} for classifiers,\n",
      " |      {'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',\n",
      " |      'median_absolute_error', 'r2'} for regressors.\n",
      " |      If a callable object or function is provided, it has to be conform with\n",
      " |      sklearn's signature ``scorer(estimator, X, y)``; see\n",
      " |      https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\n",
      " |      for more information.\n",
      " |  \n",
      " |  cv : int (default: 5)\n",
      " |      Integer or iterable yielding train, test splits. If cv is an integer\n",
      " |      and `estimator` is a classifier (or y consists of integer class\n",
      " |      labels) stratified k-fold. Otherwise regular k-fold cross-validation\n",
      " |      is performed. No cross-validation if cv is None, False, or 0.\n",
      " |  \n",
      " |  n_jobs : int (default: 1)\n",
      " |      The number of CPUs to use for evaluating different feature subsets\n",
      " |      in parallel. -1 means 'all CPUs'.\n",
      " |  \n",
      " |  pre_dispatch : int, or string (default: '2*n_jobs')\n",
      " |      Controls the number of jobs that get dispatched\n",
      " |      during parallel execution if `n_jobs > 1` or `n_jobs=-1`.\n",
      " |      Reducing this number can be useful to avoid an explosion of\n",
      " |      memory consumption when more jobs get dispatched than CPUs can process.\n",
      " |      This parameter can be:\n",
      " |      None, in which case all the jobs are immediately created and spawned.\n",
      " |          Use this for lightweight and fast-running jobs,\n",
      " |          to avoid delays due to on-demand spawning of the jobs\n",
      " |      An int, giving the exact number of total jobs that are spawned\n",
      " |      A string, giving an expression as a function\n",
      " |          of n_jobs, as in `2*n_jobs`\n",
      " |  \n",
      " |  clone_estimator : bool (default: True)\n",
      " |      Clones estimator if True; works with the original estimator instance\n",
      " |      if False. Set to False if the estimator doesn't\n",
      " |      implement scikit-learn's set_params and get_params methods.\n",
      " |      In addition, it is required to set cv=0, and n_jobs=1.\n",
      " |  \n",
      " |  fixed_features : tuple (default: None)\n",
      " |      If not `None`, the feature indices provided as a tuple will be\n",
      " |      regarded as fixed by the feature selector. For example, if\n",
      " |      `fixed_features=(1, 3, 7)`, the 2nd, 4th, and 8th feature are\n",
      " |      guaranteed to be present in the solution. Note that if\n",
      " |      `fixed_features` is not `None`, make sure that the number of\n",
      " |      features to be selected is greater than `len(fixed_features)`.\n",
      " |      In other words, ensure that `k_features > len(fixed_features)`.\n",
      " |      New in mlxtend v. 0.18.0.\n",
      " |  \n",
      " |  feature_groups : list or None (default: None)\n",
      " |      Optional argument for treating certain features as a group.\n",
      " |      This means, the features within a group are always selected together,\n",
      " |      never split.\n",
      " |      For example, `feature_groups=[[1], [2], [3, 4, 5]]`\n",
      " |      specifies 3 feature groups. In this case,\n",
      " |      possible feature selection results with `k_features=2`\n",
      " |      are `[[1], [2]`, `[[1], [3, 4, 5]]`, or `[[2], [3, 4, 5]]`.\n",
      " |      Feature groups can be useful for\n",
      " |      interpretability, for example, if features 3, 4, 5 are one-hot\n",
      " |      encoded features.  (For  more details, please read the notes at the\n",
      " |      bottom of this docstring).  New in mlxtend v. 0.21.0.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  k_feature_idx_ : array-like, shape = [n_predictions]\n",
      " |      Feature Indices of the selected feature subsets.\n",
      " |  \n",
      " |  k_feature_names_ : array-like, shape = [n_predictions]\n",
      " |      Feature names of the selected feature subsets. If pandas\n",
      " |      DataFrames are used in the `fit` method, the feature\n",
      " |      names correspond to the column names. Otherwise, the\n",
      " |      feature names are string representation of the feature\n",
      " |      array indices. New in v 0.13.0.\n",
      " |  \n",
      " |  k_score_ : float\n",
      " |      Cross validation average score of the selected subset.\n",
      " |  \n",
      " |  subsets_ : dict\n",
      " |      A dictionary of selected feature subsets during the\n",
      " |      sequential selection, where the dictionary keys are\n",
      " |      the lengths k of these feature subsets. If the parameter\n",
      " |      `feature_groups` is not None, the value of key indicates\n",
      " |      the number of groups that are selected together. The dictionary\n",
      " |      values are dictionaries themselves with the following\n",
      " |      keys: 'feature_idx' (tuple of indices of the feature subset)\n",
      " |            'feature_names' (tuple of feature names of the feat. subset)\n",
      " |            'cv_scores' (list individual cross-validation scores)\n",
      " |            'avg_score' (average cross-validation score)\n",
      " |      Note that if pandas\n",
      " |      DataFrames are used in the `fit` method, the 'feature_names'\n",
      " |      correspond to the column names. Otherwise, the\n",
      " |      feature names are string representation of the feature\n",
      " |      array indices. The 'feature_names' is new in v 0.13.0.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  (1) If parameter `feature_groups` is not None, the\n",
      " |  number of features is equal to the number of feature groups, i.e.\n",
      " |  `len(feature_groups)`. For  example, if `feature_groups = [[0], [1], [2, 3],\n",
      " |  [4]]`, then the `max_features` value cannot exceed 4.\n",
      " |  \n",
      " |  (2) Although two or more individual features may be considered as one group\n",
      " |  throughout the feature-selection process, it does not mean the individual\n",
      " |  features of that group have the same impact on the outcome. For instance, in\n",
      " |  linear regression, the coefficient of the feature 2 and 3 can be different\n",
      " |  even if they are considered as one group in feature_groups.\n",
      " |  \n",
      " |  (3) If both fixed_features and feature_groups are specified, ensure that each\n",
      " |  feature group contains the fixed_features selection. E.g., for a 3-feature set\n",
      " |  fixed_features=[0, 1] and feature_groups=[[0, 1], [2]] is valid;\n",
      " |  fixed_features=[0, 1] and feature_groups=[[0], [1, 2]] is not valid.\n",
      " |  \n",
      " |  (4) In case of KeyboardInterrupt, the dictionary subsets may not be completed.\n",
      " |  If user is still interested in getting the best score, they can use method\n",
      " |  `finalize_fit`.\n",
      " |  \n",
      " |  Examples\n",
      " |  -----------\n",
      " |  For usage examples, please see\n",
      " |  https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SequentialFeatureSelector\n",
      " |      mlxtend.utils.base_compostion._BaseXComposition\n",
      " |      sklearn.utils.metaestimators._BaseComposition\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, k_features=1, forward=True, floating=False, verbose=0, scoring=None, cv=5, n_jobs=1, pre_dispatch='2*n_jobs', clone_estimator=True, fixed_features=None, feature_groups=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  finalize_fit(self)\n",
      " |  \n",
      " |  fit(self, X, y, groups=None, **fit_params)\n",
      " |      Perform feature selection and learn model from training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for y.\n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Passed to the fit method of the cross-validator.\n",
      " |      fit_params : various, optional\n",
      " |          Additional parameters that are being passed to the estimator.\n",
      " |          For example, `sample_weights=weights`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  fit_transform(self, X, y, groups=None, **fit_params)\n",
      " |      Fit to training data then reduce X to its most important features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |          New in v 0.13.0: a pandas Series are now also accepted as\n",
      " |          argument for y.\n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Passed to the fit method of the cross-validator.\n",
      " |      fit_params : various, optional\n",
      " |          Additional parameters that are being passed to the estimator.\n",
      " |          For example, `sample_weights=weights`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Reduced feature subset of X, shape={n_samples, k_features}\n",
      " |  \n",
      " |  generate_error_message_k_features(self, name)\n",
      " |  \n",
      " |  get_metric_dict(self, confidence_interval=0.95)\n",
      " |      Return metric dictionary\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      confidence_interval : float (default: 0.95)\n",
      " |          A positive float between 0.0 and 1.0 to compute the confidence\n",
      " |          interval bounds of the CV score averages.\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      Dictionary with items where each dictionary value is a list\n",
      " |      with the number of iterations (number of feature subsets) as\n",
      " |      its length. The dictionary keys corresponding to these lists\n",
      " |      are as follows:\n",
      " |          'feature_idx': tuple of the indices of the feature subset\n",
      " |          'cv_scores': list with individual CV scores\n",
      " |          'avg_score': of CV average scores\n",
      " |          'std_dev': standard deviation of the CV score average\n",
      " |          'std_err': standard error of the CV score average\n",
      " |          'ci_bound': confidence interval bound of the CV score average\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_fit_request(self: mlxtend.feature_selection.sequential_feature_selector.SequentialFeatureSelector, *, groups: Union[bool, NoneType, str] = '$UNCHANGED$') -> mlxtend.feature_selection.sequential_feature_selector.SequentialFeatureSelector\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      groups : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``groups`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      Valid parameter keys can be listed with ``get_params()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Reduced feature subset of X, shape={n_samples, k_features}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  named_estimators\n",
      " |      Returns\n",
      " |      -------\n",
      " |      List of named estimator tuples, like [('svc', SVC(...))]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SequentialFeatureSelector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
