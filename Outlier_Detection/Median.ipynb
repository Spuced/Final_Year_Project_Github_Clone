{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details getting the median spectra for each surface and then training a model based on these median surface spectra. The aim here is to remove noisy or outlier spectra, to be left with a spectrum that is representative of the true Raman fingerprint of that surface.\n",
    "\n",
    "This notebook uses KFold cross validation as there is no data leakage between surfaces since each spectrum only represents one surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Adds the parent directory to the path so Python can find the `Cleaning_and_Evaluation` package\n",
    "from Cleaning_and_Evaluation import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/exosomes.raw_spectrum_400-1800.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_params = {\n",
    "    'despike': False,\n",
    "    'baseline_correct': True,\n",
    "    'smoothing': True,\n",
    "    'scaling': False,\n",
    "    'despike_ma': 10,\n",
    "    'despike_threshold': 7,\n",
    "    'lam': 10**9,\n",
    "    'p': 0.05,\n",
    "    'window_size': 35,\n",
    "    'poly_order': 3\n",
    "}\n",
    "spectra_cleaning(df, **cleaning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing spectra and getting median absorbance at each wavenumber within each surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wavelength_df(df, absorbance_col, status_col='Status'):\n",
    "\n",
    "    # Group by 'SurID' and 'WaveNumber' and calculate median absorbance\n",
    "    median_absorbance = df.groupby(['SurID', 'WaveNumber'])[absorbance_col].median().reset_index()\n",
    "\n",
    "    # Pivot the table to get 'WaveNumber' as columns, 'SurID' as index, and median absorbance as values\n",
    "    wavelength_df = median_absorbance.pivot(index='SurID', columns='WaveNumber', values=absorbance_col)\n",
    "\n",
    "    # Merge with the statuses based on SpecID\n",
    "    # Include the SurID to perform GroupKFold CV\n",
    "    statuses_and_surface = df[['SurID', status_col]].drop_duplicates()\n",
    "    wavelength_df = pd.merge(wavelength_df, statuses_and_surface, on='SurID')\n",
    "\n",
    "    # Set SpecID as the index\n",
    "    wavelength_df = wavelength_df.set_index('SurID')\n",
    "\n",
    "    return wavelength_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees(df):\n",
    "\n",
    "    # Set the Surfaces as groups\n",
    "    X = df.drop(['Status'], axis=1)\n",
    "    y = df['Status']\n",
    "    \n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    #cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "\n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.6071 +/- 0.1701\n"
     ]
    }
   ],
   "source": [
    "prep_df = prepare_wavelength_df(df, 'Absorbance')\n",
    "evaluate_extra_trees(prep_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
