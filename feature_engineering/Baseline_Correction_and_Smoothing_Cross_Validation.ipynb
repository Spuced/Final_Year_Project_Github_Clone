{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This aims to classify the exosome staus based on a featureset derrived from the peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test different spectral cleaning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import peak_widths\n",
    "from scipy.signal import peak_prominences\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the spectral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/exosomes.raw_spectrum_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>WaveNumber</th>\n",
       "      <th>Absorbance</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>0</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2709.3699</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>1</td>\n",
       "      <td>200.68336</td>\n",
       "      <td>2697.1318</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>2</td>\n",
       "      <td>201.36674</td>\n",
       "      <td>2696.0413</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>3</td>\n",
       "      <td>202.05011</td>\n",
       "      <td>2678.5925</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>4</td>\n",
       "      <td>202.73349</td>\n",
       "      <td>2670.8928</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023570</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2630</td>\n",
       "      <td>1997.26650</td>\n",
       "      <td>1321.0371</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023571</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2631</td>\n",
       "      <td>1997.94980</td>\n",
       "      <td>1316.4056</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023572</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2632</td>\n",
       "      <td>1998.63330</td>\n",
       "      <td>1311.2640</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023573</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2633</td>\n",
       "      <td>1999.31670</td>\n",
       "      <td>1318.0909</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023574</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2634</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>1300.7710</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8023575 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SpecID   Seq  WaveNumber  Absorbance     SurID         Status\n",
       "0        201210-1-00     0   200.00000   2709.3699  201210-1         Normal\n",
       "1        201210-1-00     1   200.68336   2697.1318  201210-1         Normal\n",
       "2        201210-1-00     2   201.36674   2696.0413  201210-1         Normal\n",
       "3        201210-1-00     3   202.05011   2678.5925  201210-1         Normal\n",
       "4        201210-1-00     4   202.73349   2670.8928  201210-1         Normal\n",
       "...              ...   ...         ...         ...       ...            ...\n",
       "8023570  210526-3-09  2630  1997.26650   1321.0371  210526-3  Hyperglycemia\n",
       "8023571  210526-3-09  2631  1997.94980   1316.4056  210526-3  Hyperglycemia\n",
       "8023572  210526-3-09  2632  1998.63330   1311.2640  210526-3  Hyperglycemia\n",
       "8023573  210526-3-09  2633  1999.31670   1318.0909  210526-3  Hyperglycemia\n",
       "8023574  210526-3-09  2634  2000.00000   1300.7710  210526-3  Hyperglycemia\n",
       "\n",
       "[8023575 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['201210-1-00', '201210-1-01', '201210-1-02', ..., '210526-3-07',\n",
       "       '210526-3-08', '210526-3-09'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SpecID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8023575 entries, 0 to 8023574\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   SpecID      object \n",
      " 1   Seq         int64  \n",
      " 2   WaveNumber  float64\n",
      " 3   Absorbance  float64\n",
      " 4   SurID       object \n",
      " 5   Status      object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 367.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train an Extra Trees Classifier on the full spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wavelength_df(df, absorbance_col, status_col='Status'):\n",
    "\n",
    "    # Pivot the DataFrame to get wavelengths as columns and absorbance values\n",
    "    wavelength_df = df.pivot(index='SpecID', columns='WaveNumber', values=absorbance_col).reset_index()\n",
    "    wavelength_df.columns.name = None\n",
    "\n",
    "    # Merge with the statuses based on SpecID\n",
    "    statuses = df[['SpecID', status_col]].drop_duplicates()\n",
    "    wavelength_df = pd.merge(wavelength_df, statuses, on='SpecID')\n",
    "\n",
    "    # Set SpecID as the index\n",
    "    wavelength_df = wavelength_df.set_index('SpecID')\n",
    "\n",
    "    return wavelength_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_df = prepare_wavelength_df(df, 'Absorbance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200.0</th>\n",
       "      <th>200.68336</th>\n",
       "      <th>201.36674</th>\n",
       "      <th>202.05011</th>\n",
       "      <th>202.73349</th>\n",
       "      <th>203.41685</th>\n",
       "      <th>204.10023</th>\n",
       "      <th>204.7836</th>\n",
       "      <th>205.46696</th>\n",
       "      <th>206.15034</th>\n",
       "      <th>...</th>\n",
       "      <th>1994.5331</th>\n",
       "      <th>1995.2164</th>\n",
       "      <th>1995.8998</th>\n",
       "      <th>1996.5831</th>\n",
       "      <th>1997.2665</th>\n",
       "      <th>1997.9498</th>\n",
       "      <th>1998.6333</th>\n",
       "      <th>1999.3167</th>\n",
       "      <th>2000.0</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>2709.3699</td>\n",
       "      <td>2697.1318</td>\n",
       "      <td>2696.0413</td>\n",
       "      <td>2678.5925</td>\n",
       "      <td>2670.8928</td>\n",
       "      <td>2652.5435</td>\n",
       "      <td>2646.3245</td>\n",
       "      <td>2690.3240</td>\n",
       "      <td>2620.3228</td>\n",
       "      <td>2609.0132</td>\n",
       "      <td>...</td>\n",
       "      <td>1100.5006</td>\n",
       "      <td>1088.7416</td>\n",
       "      <td>1092.1083</td>\n",
       "      <td>1104.9304</td>\n",
       "      <td>1084.1281</td>\n",
       "      <td>1076.9363</td>\n",
       "      <td>1089.0814</td>\n",
       "      <td>1092.8083</td>\n",
       "      <td>1086.6990</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>2979.3169</td>\n",
       "      <td>2985.7070</td>\n",
       "      <td>2970.1677</td>\n",
       "      <td>2947.0950</td>\n",
       "      <td>2941.8743</td>\n",
       "      <td>2942.4648</td>\n",
       "      <td>2939.9595</td>\n",
       "      <td>2938.4509</td>\n",
       "      <td>2930.9204</td>\n",
       "      <td>2915.7979</td>\n",
       "      <td>...</td>\n",
       "      <td>1246.2748</td>\n",
       "      <td>1270.4456</td>\n",
       "      <td>1272.1703</td>\n",
       "      <td>1271.8768</td>\n",
       "      <td>1270.0718</td>\n",
       "      <td>1283.9667</td>\n",
       "      <td>1286.9803</td>\n",
       "      <td>1276.4037</td>\n",
       "      <td>1268.0922</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>3702.5627</td>\n",
       "      <td>3592.4902</td>\n",
       "      <td>3640.8423</td>\n",
       "      <td>3593.4150</td>\n",
       "      <td>3583.6560</td>\n",
       "      <td>3583.4790</td>\n",
       "      <td>3554.3279</td>\n",
       "      <td>3507.1514</td>\n",
       "      <td>3494.4998</td>\n",
       "      <td>3490.4370</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.6669</td>\n",
       "      <td>2046.8510</td>\n",
       "      <td>2094.8308</td>\n",
       "      <td>2067.8396</td>\n",
       "      <td>2043.0687</td>\n",
       "      <td>2063.5925</td>\n",
       "      <td>2086.6956</td>\n",
       "      <td>2064.7766</td>\n",
       "      <td>2064.2126</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>8129.5938</td>\n",
       "      <td>8222.3184</td>\n",
       "      <td>8370.2803</td>\n",
       "      <td>8534.4150</td>\n",
       "      <td>8684.1543</td>\n",
       "      <td>8805.7393</td>\n",
       "      <td>8964.5283</td>\n",
       "      <td>9220.3066</td>\n",
       "      <td>9257.7461</td>\n",
       "      <td>9399.7734</td>\n",
       "      <td>...</td>\n",
       "      <td>1682.3824</td>\n",
       "      <td>1694.8450</td>\n",
       "      <td>1710.2760</td>\n",
       "      <td>1714.6768</td>\n",
       "      <td>1746.4635</td>\n",
       "      <td>1705.4204</td>\n",
       "      <td>1703.1569</td>\n",
       "      <td>1705.2943</td>\n",
       "      <td>1687.0480</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>3468.5203</td>\n",
       "      <td>3463.0237</td>\n",
       "      <td>3475.2666</td>\n",
       "      <td>3468.5999</td>\n",
       "      <td>3451.7124</td>\n",
       "      <td>3439.6379</td>\n",
       "      <td>3439.1538</td>\n",
       "      <td>3444.8345</td>\n",
       "      <td>3446.6240</td>\n",
       "      <td>3438.2632</td>\n",
       "      <td>...</td>\n",
       "      <td>1725.4711</td>\n",
       "      <td>1722.2786</td>\n",
       "      <td>1757.0481</td>\n",
       "      <td>1745.6029</td>\n",
       "      <td>1728.0017</td>\n",
       "      <td>1750.2548</td>\n",
       "      <td>1747.0122</td>\n",
       "      <td>1756.1727</td>\n",
       "      <td>1747.9722</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 200.0  200.68336  201.36674  202.05011  202.73349  203.41685  \\\n",
       "SpecID                                                                          \n",
       "201210-1-00  2709.3699  2697.1318  2696.0413  2678.5925  2670.8928  2652.5435   \n",
       "201210-1-01  2979.3169  2985.7070  2970.1677  2947.0950  2941.8743  2942.4648   \n",
       "201210-1-02  3702.5627  3592.4902  3640.8423  3593.4150  3583.6560  3583.4790   \n",
       "201210-1-03  8129.5938  8222.3184  8370.2803  8534.4150  8684.1543  8805.7393   \n",
       "201210-1-04  3468.5203  3463.0237  3475.2666  3468.5999  3451.7124  3439.6379   \n",
       "\n",
       "             204.10023   204.7836  205.46696  206.15034  ...  1994.5331  \\\n",
       "SpecID                                                   ...              \n",
       "201210-1-00  2646.3245  2690.3240  2620.3228  2609.0132  ...  1100.5006   \n",
       "201210-1-01  2939.9595  2938.4509  2930.9204  2915.7979  ...  1246.2748   \n",
       "201210-1-02  3554.3279  3507.1514  3494.4998  3490.4370  ...  2028.6669   \n",
       "201210-1-03  8964.5283  9220.3066  9257.7461  9399.7734  ...  1682.3824   \n",
       "201210-1-04  3439.1538  3444.8345  3446.6240  3438.2632  ...  1725.4711   \n",
       "\n",
       "             1995.2164  1995.8998  1996.5831  1997.2665  1997.9498  1998.6333  \\\n",
       "SpecID                                                                          \n",
       "201210-1-00  1088.7416  1092.1083  1104.9304  1084.1281  1076.9363  1089.0814   \n",
       "201210-1-01  1270.4456  1272.1703  1271.8768  1270.0718  1283.9667  1286.9803   \n",
       "201210-1-02  2046.8510  2094.8308  2067.8396  2043.0687  2063.5925  2086.6956   \n",
       "201210-1-03  1694.8450  1710.2760  1714.6768  1746.4635  1705.4204  1703.1569   \n",
       "201210-1-04  1722.2786  1757.0481  1745.6029  1728.0017  1750.2548  1747.0122   \n",
       "\n",
       "             1999.3167     2000.0  Status  \n",
       "SpecID                                     \n",
       "201210-1-00  1092.8083  1086.6990  Normal  \n",
       "201210-1-01  1276.4037  1268.0922  Normal  \n",
       "201210-1-02  2064.7766  2064.2126  Normal  \n",
       "201210-1-03  1705.2943  1687.0480  Normal  \n",
       "201210-1-04  1756.1727  1747.9722  Normal  \n",
       "\n",
       "[5 rows x 2636 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(absorbances):\n",
    "    max_value = np.max(absorbances)\n",
    "    normalized_absorbances = absorbances / max_value\n",
    "    return normalized_absorbances\n",
    "\n",
    "df['Scaled_Absorbance'] = df.groupby('SpecID')['Absorbance'].transform(lambda x: normalise(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Calculate the baseline using Asymmetric Least Squares, then subtract it from the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_als_optimized(y, lam, p, niter=10):\n",
    "    L = len(y)\n",
    "    D = sparse.diags([1,-2,1],[0,-1,-2], shape=(L,L-2))\n",
    "    D = lam * D.dot(D.transpose()) # Precompute this term since it does not depend on `w`\n",
    "    w = np.ones(L)\n",
    "    W = sparse.spdiags(w, 0, L, L)\n",
    "    for i in range(niter):\n",
    "        W.setdiag(w) # Do not create a new matrix, just update diagonal values\n",
    "        Z = W + D\n",
    "        z = spsolve(Z, w*y)\n",
    "        w = p * (y > z) + (1-p) * (y < z)\n",
    "    return z\n",
    "\n",
    "# lam = 10 ** 8\n",
    "# p = 0.05\n",
    "# df['Baseline_Corrected_Absorbance'] = df.groupby('SpecID')['Despiked_Absorbance'].transform(lambda x: baseline_als_optimized(x, lam=lam, p=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Perform Grid-Search to find the best Assymetric Least Squares Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>WaveNumber</th>\n",
       "      <th>Absorbance</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>0</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2709.3699</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>1</td>\n",
       "      <td>200.68336</td>\n",
       "      <td>2697.1318</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>2</td>\n",
       "      <td>201.36674</td>\n",
       "      <td>2696.0413</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>3</td>\n",
       "      <td>202.05011</td>\n",
       "      <td>2678.5925</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>4</td>\n",
       "      <td>202.73349</td>\n",
       "      <td>2670.8928</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023570</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2630</td>\n",
       "      <td>1997.26650</td>\n",
       "      <td>1321.0371</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023571</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2631</td>\n",
       "      <td>1997.94980</td>\n",
       "      <td>1316.4056</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023572</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2632</td>\n",
       "      <td>1998.63330</td>\n",
       "      <td>1311.2640</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023573</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2633</td>\n",
       "      <td>1999.31670</td>\n",
       "      <td>1318.0909</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023574</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2634</td>\n",
       "      <td>2000.00000</td>\n",
       "      <td>1300.7710</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8023575 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SpecID   Seq  WaveNumber  Absorbance     SurID         Status\n",
       "0        201210-1-00     0   200.00000   2709.3699  201210-1         Normal\n",
       "1        201210-1-00     1   200.68336   2697.1318  201210-1         Normal\n",
       "2        201210-1-00     2   201.36674   2696.0413  201210-1         Normal\n",
       "3        201210-1-00     3   202.05011   2678.5925  201210-1         Normal\n",
       "4        201210-1-00     4   202.73349   2670.8928  201210-1         Normal\n",
       "...              ...   ...         ...         ...       ...            ...\n",
       "8023570  210526-3-09  2630  1997.26650   1321.0371  210526-3  Hyperglycemia\n",
       "8023571  210526-3-09  2631  1997.94980   1316.4056  210526-3  Hyperglycemia\n",
       "8023572  210526-3-09  2632  1998.63330   1311.2640  210526-3  Hyperglycemia\n",
       "8023573  210526-3-09  2633  1999.31670   1318.0909  210526-3  Hyperglycemia\n",
       "8023574  210526-3-09  2634  2000.00000   1300.7710  210526-3  Hyperglycemia\n",
       "\n",
       "[8023575 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: lam=100000, p=0.001 with Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "# lam_values = [10**4, 10**5, 10**6, 10**7]\n",
    "# p_values = [0.001, 0.01, 0.02, 0.1]\n",
    "\n",
    "lam_values = [10 ** 3, 10**4, 10**5, 10**6, 10**7]\n",
    "p_values = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for lam in lam_values:\n",
    "    for p in p_values:\n",
    "        \n",
    "        # Apply baseline correction with current lam and p\n",
    "        df['Baseline_Corrected_Absorbance'] = df['Absorbance'] - df.groupby('SpecID')['Absorbance'].transform(lambda x: baseline_als_optimized(x, lam=lam, p=p))\n",
    "        \n",
    "        baseline_corrected_df = prepare_wavelength_df(df, 'Baseline_Corrected_Absorbance')\n",
    "        # Splitting the dataframe into features and target variable\n",
    "        X = baseline_corrected_df.drop(['Status'], axis=1)\n",
    "        y = baseline_corrected_df['Status']\n",
    "        \n",
    "        # Create the Extra Trees classifier\n",
    "        et = ExtraTreesClassifier(random_state=1234)\n",
    "        cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "        \n",
    "        # Perform cross-validation and store results\n",
    "        scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "        results.append(((lam, p), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: lam={best_params[0]}, p={best_params[1]} with Accuracy: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lam</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883097</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878499</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lam  P-Value  Mean Accuracy  Standard Deviation\n",
       "1    7        2       0.883097            0.015886\n",
       "0    5        2       0.878499            0.016681"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Lam', 'P-Value']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Lam', 'P-Value', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Baseline_Removal_Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Try with Different Smoothing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: window_size=7, poly_order=2 with Accuracy: 0.8831\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "\n",
    "# window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "# poly_order = [1, 2, 3, 5]\n",
    "window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "poly_order = [1, 2, 3]\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for window in window_size:\n",
    "    for poly in poly_order:\n",
    "\n",
    "        # Apply smoothing with the current parameters\n",
    "        df['Smoothed_Absorbance'] = df.groupby('SpecID')['Absorbance'].transform(lambda x: savgol_filter(x, window, poly, deriv=0))\n",
    "        \n",
    "        smoothed_df = prepare_wavelength_df(df, 'Smoothed_Absorbance')\n",
    "\n",
    "        # Splitting the dataframe into features and target variable\n",
    "        X = smoothed_df.drop(['Status'], axis=1)\n",
    "        y = smoothed_df['Status']\n",
    "        \n",
    "        # Create the Extra Trees classifier\n",
    "        et = ExtraTreesClassifier(random_state=1234)\n",
    "        cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "        \n",
    "        # Perform cross-validation and store results\n",
    "        scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "        results.append(((window, poly), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: window_size={best_params[0]}, poly_order={best_params[1]} with Accuracy: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Polynomial Order</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883097</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878499</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size  Polynomial Order  Mean Accuracy  Standard Deviation\n",
       "1            7                 2       0.883097            0.015886\n",
       "0            5                 2       0.878499            0.016681"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Window Size', 'Polynomial Order']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Window Size', 'Polynomial Order', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Smoothing_Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##### Try with both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: lam=10000, p=0.001, window_size=5, poly_order=1 with Accuracy: 0.8831\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "# lam_values = [10**4, 10**5, 10**6, 10**7]\n",
    "# p_values = [0.001, 0.01, 0.02, 0.1]\n",
    "# window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "# poly_order = [1, 2, 3]\n",
    "\n",
    "lam_values = [10 ** 3, 10**4, 10**5, 10**6, 10**7]\n",
    "p_values = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "poly_order = [1, 2, 3]\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for lam in lam_values:\n",
    "    for p in p_values:\n",
    "        \n",
    "        # Apply baseline correction with current lam and p\n",
    "        df['Baseline_Corrected_Absorbance'] = df['Absorbance'] - df.groupby('SpecID')['Absorbance'].transform(lambda x: baseline_als_optimized(x, lam=lam, p=p))\n",
    "                \n",
    "        for window in window_size:\n",
    "            for poly in poly_order:\n",
    "\n",
    "                # Apply smoothing with the current parameters\n",
    "                df['Smoothed_Baseline'] = df.groupby('SpecID')['Baseline_Corrected_Absorbance'].transform(lambda x: savgol_filter(x, window, poly, deriv=0))\n",
    "                \n",
    "                smoothed_baseline = prepare_wavelength_df(df, 'Smoothed_Baseline')\n",
    "\n",
    "                # Splitting the dataframe into features and target variable\n",
    "                X = smoothed_df.drop(['Status'], axis=1)\n",
    "                y = smoothed_df['Status']\n",
    "                \n",
    "                # Create the Extra Trees classifier\n",
    "                et = ExtraTreesClassifier(random_state=1234)\n",
    "                cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "                \n",
    "                # Perform cross-validation and store results\n",
    "                scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "                results.append(((lam, p, window, poly), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: lam={best_params[0]}, p={best_params[1]}, window_size={best_params[2]}, poly_order={best_params[3]} with Accuracy: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Polynomial Order</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883097</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size  Polynomial Order  Mean Accuracy  Standard Deviation\n",
       "0            5                 1       0.883097            0.015886"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Lam', 'P-Value', 'Window Size', 'Polynomial Order']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Window Size', 'Polynomial Order', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Smoothed_Baseline_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Finally Try this using again with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lam_values:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m p_values:\n\u001b[1;32m     13\u001b[0m         \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply baseline correction with current lam and p\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline_Corrected_Absorbance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbsorbance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpecID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAbsorbance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_als_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScaled_Baseline\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecID\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline_Corrected_Absorbance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: normalise(x))\n\u001b[1;32m     18\u001b[0m         scaled_baseline \u001b[38;5;241m=\u001b[39m prepare_wavelength_df(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScaled_Baseline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/generic.py:516\u001b[0m, in \u001b[0;36mSeriesGroupBy.transform\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(klass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m, example\u001b[38;5;241m=\u001b[39m__examples_series_doc)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_transform_template)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1950\u001b[0m, in \u001b[0;36mGroupBy._transform\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, func)\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m func \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m base\u001b[38;5;241m.\u001b[39mtransform_kernel_allowlist:\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid function name for transform(name)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/generic.py:556\u001b[0m, in \u001b[0;36mSeriesGroupBy._transform_general\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[1;32m    553\u001b[0m ):\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# this setattr is needed for test_transform_lambda_with_datetimetz\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m--> 556\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(klass(res, index\u001b[38;5;241m=\u001b[39mgroup\u001b[38;5;241m.\u001b[39mindex))\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# check for empty \"results\" to avoid concat ValueError\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lam_values:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m p_values:\n\u001b[1;32m     13\u001b[0m         \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply baseline correction with current lam and p\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline_Corrected_Absorbance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbsorbance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecID\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbsorbance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mbaseline_als_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScaled_Baseline\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecID\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline_Corrected_Absorbance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: normalise(x))\n\u001b[1;32m     18\u001b[0m         scaled_baseline \u001b[38;5;241m=\u001b[39m prepare_wavelength_df(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScaled_Baseline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mbaseline_als_optimized\u001b[0;34m(y, lam, p, niter)\u001b[0m\n\u001b[1;32m      8\u001b[0m     W\u001b[38;5;241m.\u001b[39msetdiag(w) \u001b[38;5;66;03m# Do not create a new matrix, just update diagonal values\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     Z \u001b[38;5;241m=\u001b[39m W \u001b[38;5;241m+\u001b[39m D\n\u001b[0;32m---> 10\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mspsolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     w \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m>\u001b[39m z) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m<\u001b[39m z)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:290\u001b[0m, in \u001b[0;36mspsolve\u001b[0;34m(A, b, permc_spec, use_umfpack)\u001b[0m\n\u001b[1;32m    288\u001b[0m indptr \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mintc, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    289\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ColPerm\u001b[38;5;241m=\u001b[39mpermc_spec)\n\u001b[0;32m--> 290\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43m_superlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgssv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix is exactly singular\u001b[39m\u001b[38;5;124m\"\u001b[39m, MatrixRankWarning)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "# lam_values = [10**4, 10**5, 10**6, 10**7]\n",
    "# p_values = [0.001, 0.01, 0.02, 0.1]\n",
    "\n",
    "lam_values = [10 ** 3, 10**4, 10**5, 10**6, 10**7]\n",
    "p_values = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for lam in lam_values:\n",
    "    for p in p_values:\n",
    "        \n",
    "        # Apply baseline correction with current lam and p\n",
    "        df['Baseline_Corrected_Absorbance'] = df['Absorbance'] - df.groupby('SpecID')['Absorbance'].transform(lambda x: baseline_als_optimized(x, lam=lam, p=p))\n",
    "        df['Scaled_Baseline'] = df.groupby('SpecID')['Baseline_Corrected_Absorbance'].transform(lambda x: normalise(x))\n",
    "        \n",
    "        scaled_baseline = prepare_wavelength_df(df, 'Scaled_Baseline')\n",
    "        # Splitting the dataframe into features and target variable\n",
    "        X = scaled_baseline.drop(['Status'], axis=1)\n",
    "        y = scaled_baseline['Status']\n",
    "        \n",
    "        # Create the Extra Trees classifier\n",
    "        et = ExtraTreesClassifier(random_state=1234)\n",
    "        cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "        \n",
    "        # Perform cross-validation and store results\n",
    "        scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "        results.append(((lam, p), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: lam={best_params[0]}, p={best_params[1]} with Accuracy: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lam</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.776039</td>\n",
       "      <td>0.026831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lam  P-Value  Mean Accuracy  Standard Deviation\n",
       "0  1000    0.001       0.776039            0.026831"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Lam', 'P-Value']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Lam', 'P-Value', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Scaled_Baseline_Removal_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: window_size=7, poly_order=2 with Accuracy: 0.8831\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "\n",
    "# window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "# poly_order = [1, 2, 3, 5]\n",
    "\n",
    "window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "poly_order = [1, 2, 3]\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for window in window_size:\n",
    "    for poly in poly_order:\n",
    "\n",
    "        # Apply smoothing with the current parameters\n",
    "        df['Smoothed_Absorbance'] = df.groupby('SpecID')['Absorbance'].transform(lambda x: savgol_filter(x, window, poly, deriv=0))\n",
    "        df['Scaled_Smoothing'] = df.groupby('SpecID')['Smoothed_Absorbance'].transform(lambda x: normalise(x))\n",
    "        \n",
    "        scaled_smoothed_df = prepare_wavelength_df(df, 'Scaled_Smoothing')\n",
    "\n",
    "        # Splitting the dataframe into features and target variable\n",
    "        X = scaled_smoothed_df.drop(['Status'], axis=1)\n",
    "        y = scaled_smoothed_df['Status']\n",
    "        \n",
    "        # Create the Extra Trees classifier\n",
    "        et = ExtraTreesClassifier(random_state=1234)\n",
    "        cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "        \n",
    "        # Perform cross-validation and store results\n",
    "        scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "        results.append(((window, poly), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: window_size={best_params[0]}, poly_order={best_params[1]} with Accuracy: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Polynomial Order</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883097</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878499</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size  Polynomial Order  Mean Accuracy  Standard Deviation\n",
       "1            7                 2       0.883097            0.015886\n",
       "0            5                 2       0.878499            0.016681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Window Size', 'Polynomial Order']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Window Size', 'Polynomial Order', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Scaled_Smoothing_Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##### Try with both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: lam=10000, p=0.001, window_size=5, poly_order=1 with Accuracy: 0.8831\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "lam_values = [10 ** 3, 10**4, 10**5, 10**6, 10**7]\n",
    "p_values = [0.001, 0.01, 0.02, 0.05, 0.1]\n",
    "window_size = [5, 7, 9, 19, 25, 51, 101, 151, 251]\n",
    "poly_order = [1, 2, 3]\n",
    "\n",
    "# Placeholder for storing results\n",
    "results = []\n",
    "\n",
    "for lam in lam_values:\n",
    "    for p in p_values:\n",
    "        \n",
    "        # Apply baseline correction with current lam and p\n",
    "        df['Baseline_Corrected_Absorbance'] = df['Absorbance'] - df.groupby('SpecID')['Absorbance'].transform(lambda x: baseline_als_optimized(x, lam=lam, p=p))\n",
    "                \n",
    "        for window in window_size:\n",
    "            for poly in poly_order:\n",
    "\n",
    "                # Apply smoothing with the current parameters\n",
    "                df['Smoothed_Baseline'] = df.groupby('SpecID')['Baseline_Corrected_Absorbance'].transform(lambda x: savgol_filter(x, window, poly, deriv=0))\n",
    "                df['Scaled_Baseline'] = df.groupby('SpecID')['Smoothed_Baseline'].transform(lambda x: normalise(x))\n",
    "                scaled_baseline = prepare_wavelength_df(df, 'Scaled_Baseline')\n",
    "\n",
    "                # Splitting the dataframe into features and target variable\n",
    "                X = scaled_baseline.drop(['Status'], axis=1)\n",
    "                y = scaled_baseline['Status']\n",
    "                \n",
    "                # Create the Extra Trees classifier\n",
    "                et = ExtraTreesClassifier(random_state=1234)\n",
    "                cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "                \n",
    "                # Perform cross-validation and store results\n",
    "                scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy')\n",
    "                results.append(((lam, p, window, poly), np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params, best_score, _ = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best Parameters: lam={best_params[0]}, p={best_params[1]}, window_size={best_params[2]}, poly_order={best_params[3]} with Accuracy: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Polynomial Order</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883097</td>\n",
       "      <td>0.015886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Window Size  Polynomial Order  Mean Accuracy  Standard Deviation\n",
       "0            5                 1       0.883097            0.015886"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "# Split the Parameters tuple into separate columns\n",
    "results_df[['Lam', 'P-Value', 'Window Size', 'Polynomial Order']] = pd.DataFrame(results_df['Parameters'].tolist(), index=results_df.index)\n",
    "results_df.drop(columns=['Parameters'], inplace=True)\n",
    "results_df = results_df[['Window Size', 'Polynomial Order', 'Mean Accuracy', 'Standard Deviation']].sort_values('Mean Accuracy', ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Scaled_Smoothed_Baseline_Results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
