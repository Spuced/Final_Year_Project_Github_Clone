{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/pivoted_scaled_and_noise_removal.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200.0</th>\n",
       "      <th>200.68336</th>\n",
       "      <th>201.36674</th>\n",
       "      <th>202.05011</th>\n",
       "      <th>202.73349</th>\n",
       "      <th>203.41685</th>\n",
       "      <th>204.10023</th>\n",
       "      <th>204.7836</th>\n",
       "      <th>205.46696</th>\n",
       "      <th>206.15034</th>\n",
       "      <th>...</th>\n",
       "      <th>1994.5331</th>\n",
       "      <th>1995.2164</th>\n",
       "      <th>1995.8998</th>\n",
       "      <th>1996.5831</th>\n",
       "      <th>1997.2665</th>\n",
       "      <th>1997.9498</th>\n",
       "      <th>1998.6333</th>\n",
       "      <th>1999.3167</th>\n",
       "      <th>2000.0</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982870</td>\n",
       "      <td>0.966481</td>\n",
       "      <td>0.950833</td>\n",
       "      <td>0.935925</td>\n",
       "      <td>0.927346</td>\n",
       "      <td>0.902431</td>\n",
       "      <td>0.889797</td>\n",
       "      <td>0.880243</td>\n",
       "      <td>0.864841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070690</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.090970</td>\n",
       "      <td>0.092890</td>\n",
       "      <td>0.083230</td>\n",
       "      <td>0.082239</td>\n",
       "      <td>0.082605</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980550</td>\n",
       "      <td>0.964007</td>\n",
       "      <td>0.950373</td>\n",
       "      <td>0.939647</td>\n",
       "      <td>0.930871</td>\n",
       "      <td>0.928574</td>\n",
       "      <td>0.925606</td>\n",
       "      <td>0.914910</td>\n",
       "      <td>0.900030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113337</td>\n",
       "      <td>0.117351</td>\n",
       "      <td>0.131463</td>\n",
       "      <td>0.146428</td>\n",
       "      <td>0.158236</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>0.160516</td>\n",
       "      <td>0.154980</td>\n",
       "      <td>0.144994</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>0.502527</td>\n",
       "      <td>0.491051</td>\n",
       "      <td>0.479540</td>\n",
       "      <td>0.467993</td>\n",
       "      <td>0.456410</td>\n",
       "      <td>0.450161</td>\n",
       "      <td>0.431959</td>\n",
       "      <td>0.424441</td>\n",
       "      <td>0.417415</td>\n",
       "      <td>0.408823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144569</td>\n",
       "      <td>0.141991</td>\n",
       "      <td>0.139207</td>\n",
       "      <td>0.144627</td>\n",
       "      <td>0.149526</td>\n",
       "      <td>0.150847</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.148786</td>\n",
       "      <td>0.145404</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>0.492251</td>\n",
       "      <td>0.418315</td>\n",
       "      <td>0.375666</td>\n",
       "      <td>0.364304</td>\n",
       "      <td>0.384230</td>\n",
       "      <td>0.461173</td>\n",
       "      <td>0.570848</td>\n",
       "      <td>0.577491</td>\n",
       "      <td>0.675831</td>\n",
       "      <td>0.807648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994372</td>\n",
       "      <td>0.989487</td>\n",
       "      <td>0.985346</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>0.976845</td>\n",
       "      <td>0.970762</td>\n",
       "      <td>0.977536</td>\n",
       "      <td>0.981513</td>\n",
       "      <td>0.963198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.041845</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>0.063852</td>\n",
       "      <td>0.070008</td>\n",
       "      <td>0.074530</td>\n",
       "      <td>0.077417</td>\n",
       "      <td>0.078669</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                200.0  200.68336  201.36674  202.05011  202.73349  203.41685  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00  1.000000   0.982870   0.966481   0.950833   0.935925   0.927346   \n",
       "201210-1-01  1.000000   0.980550   0.964007   0.950373   0.939647   0.930871   \n",
       "201210-1-02  0.502527   0.491051   0.479540   0.467993   0.456410   0.450161   \n",
       "201210-1-03  0.492251   0.418315   0.375666   0.364304   0.384230   0.461173   \n",
       "201210-1-04  1.000000   0.994372   0.989487   0.985346   0.981948   0.976845   \n",
       "\n",
       "             204.10023  204.7836  205.46696  206.15034  ...  1994.5331  \\\n",
       "SpecID                                                  ...              \n",
       "201210-1-00   0.902431  0.889797   0.880243   0.864841  ...   0.070690   \n",
       "201210-1-01   0.928574  0.925606   0.914910   0.900030  ...   0.113337   \n",
       "201210-1-02   0.431959  0.424441   0.417415   0.408823  ...   0.144569   \n",
       "201210-1-03   0.570848  0.577491   0.675831   0.807648  ...   0.005644   \n",
       "201210-1-04   0.970762  0.977536   0.981513   0.963198  ...   0.019359   \n",
       "\n",
       "             1995.2164  1995.8998  1996.5831  1997.2665  1997.9498  1998.6333  \\\n",
       "SpecID                                                                          \n",
       "201210-1-00   0.082414   0.090970   0.092890   0.083230   0.082239   0.082605   \n",
       "201210-1-01   0.117351   0.131463   0.146428   0.158236   0.161601   0.160516   \n",
       "201210-1-02   0.141991   0.139207   0.144627   0.149526   0.150847   0.150600   \n",
       "201210-1-03   0.007747   0.008992   0.010157   0.011991   0.011822   0.010642   \n",
       "201210-1-04   0.028442   0.041845   0.058730   0.063852   0.070008   0.074530   \n",
       "\n",
       "             1999.3167    2000.0  Status  \n",
       "SpecID                                    \n",
       "201210-1-00   0.084328  0.087409  Normal  \n",
       "201210-1-01   0.154980  0.144994  Normal  \n",
       "201210-1-02   0.148786  0.145404  Normal  \n",
       "201210-1-03   0.008451  0.005248  Normal  \n",
       "201210-1-04   0.077417  0.078669  Normal  \n",
       "\n",
       "[5 rows x 2636 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Gausian Kernal Function to Map the Euclidian Distance between all the samples between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the euclidean distance between each pair of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Drop the 'Status' column as it is not numeric\n",
    "X = df.drop(columns=['Status'])\n",
    "\n",
    "# Calculate pairwise Euclidean distances\n",
    "distances = pdist(X.values, metric='euclidean')\n",
    "\n",
    "# Convert the condensed distances to a square matrix form\n",
    "distance_matrix = squareform(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the Gaussian Kernel.\n",
    "\n",
    "Different Sigmas should be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian_kernel(distances, sigma):\n",
    "    return np.exp(-distances**2 / (2 * sigma**2))\n",
    "\n",
    "# Sigma is the bandwidth parameter\n",
    "sigma = 2 # Adjust sigma as needed\n",
    "kernel_matrix = gaussian_kernel(distance_matrix, sigma)\n",
    "\n",
    "# Convert the kernel matrix to a DataFrame\n",
    "kernel_df = pd.DataFrame(kernel_matrix, index=df.index, columns=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SpecID</th>\n",
       "      <th>201210-1-00</th>\n",
       "      <th>201210-1-01</th>\n",
       "      <th>201210-1-02</th>\n",
       "      <th>201210-1-03</th>\n",
       "      <th>201210-1-04</th>\n",
       "      <th>201210-1-05</th>\n",
       "      <th>201210-1-06</th>\n",
       "      <th>201210-1-07</th>\n",
       "      <th>201210-1-09</th>\n",
       "      <th>201210-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>210526-3-40</th>\n",
       "      <th>210526-3-41</th>\n",
       "      <th>210526-3-42</th>\n",
       "      <th>210526-3-43</th>\n",
       "      <th>210526-3-44</th>\n",
       "      <th>210526-3-45</th>\n",
       "      <th>210526-3-46</th>\n",
       "      <th>210526-3-47</th>\n",
       "      <th>210526-3-48</th>\n",
       "      <th>210526-3-49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498621</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.116846</td>\n",
       "      <td>0.087971</td>\n",
       "      <td>0.074254</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>0.019031</td>\n",
       "      <td>0.027628</td>\n",
       "      <td>0.024572</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.033534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>0.498621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.031270</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.103411</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>0.110719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>0.021558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.031270</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.069924</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.002989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407746</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.014931</td>\n",
       "      <td>0.023701</td>\n",
       "      <td>0.023082</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.025232</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.027837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-45</th>\n",
       "      <td>0.027628</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566961</td>\n",
       "      <td>0.510720</td>\n",
       "      <td>0.438520</td>\n",
       "      <td>0.535863</td>\n",
       "      <td>0.542634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545757</td>\n",
       "      <td>0.485496</td>\n",
       "      <td>0.523684</td>\n",
       "      <td>0.469168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-46</th>\n",
       "      <td>0.024572</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.014614</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559920</td>\n",
       "      <td>0.548778</td>\n",
       "      <td>0.411034</td>\n",
       "      <td>0.569511</td>\n",
       "      <td>0.521280</td>\n",
       "      <td>0.545757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>0.521503</td>\n",
       "      <td>0.482807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-47</th>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.025232</td>\n",
       "      <td>0.029996</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448601</td>\n",
       "      <td>0.420765</td>\n",
       "      <td>0.333019</td>\n",
       "      <td>0.430109</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>0.485496</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429772</td>\n",
       "      <td>0.470131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-48</th>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546158</td>\n",
       "      <td>0.510684</td>\n",
       "      <td>0.369582</td>\n",
       "      <td>0.542970</td>\n",
       "      <td>0.524964</td>\n",
       "      <td>0.523684</td>\n",
       "      <td>0.521503</td>\n",
       "      <td>0.429772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-49</th>\n",
       "      <td>0.033534</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508259</td>\n",
       "      <td>0.424111</td>\n",
       "      <td>0.330363</td>\n",
       "      <td>0.471578</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.469168</td>\n",
       "      <td>0.482807</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.455532</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 3045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SpecID       201210-1-00  201210-1-01  201210-1-02  201210-1-03  201210-1-04  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     1.000000     0.498621     0.001474     0.033503     0.139113   \n",
       "201210-1-01     0.498621     1.000000     0.003655     0.031270     0.135313   \n",
       "201210-1-02     0.001474     0.003655     1.000000     0.034599     0.000063   \n",
       "201210-1-03     0.033503     0.031270     0.034599     1.000000     0.002231   \n",
       "201210-1-04     0.139113     0.135313     0.000063     0.002231     1.000000   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.027628     0.019022     0.000095     0.002444     0.027218   \n",
       "210526-3-46     0.024572     0.015977     0.000061     0.001509     0.028355   \n",
       "210526-3-47     0.033234     0.022697     0.000315     0.004226     0.025232   \n",
       "210526-3-48     0.023375     0.015352     0.000047     0.001383     0.025729   \n",
       "210526-3-49     0.033534     0.021558     0.000144     0.002989     0.027837   \n",
       "\n",
       "SpecID       201210-1-05  201210-1-06  201210-1-07  201210-1-09  201210-1-10  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     0.147200     0.116846     0.087971     0.074254     0.107226   \n",
       "201210-1-01     0.145222     0.166514     0.103411     0.099525     0.110719   \n",
       "201210-1-02     0.000158     0.000556     0.002848     0.002976     0.001750   \n",
       "201210-1-03     0.003921     0.022159     0.105841     0.069924     0.037440   \n",
       "201210-1-04     0.407746     0.063997     0.015887     0.011784     0.027026   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.030038     0.017157     0.005321     0.003133     0.009699   \n",
       "210526-3-46     0.031541     0.014614     0.004096     0.002500     0.008301   \n",
       "210526-3-47     0.029996     0.016999     0.006487     0.003978     0.010836   \n",
       "210526-3-48     0.024952     0.013394     0.003441     0.002066     0.007276   \n",
       "210526-3-49     0.032010     0.017971     0.006528     0.003910     0.011465   \n",
       "\n",
       "SpecID       ...  210526-3-40  210526-3-41  210526-3-42  210526-3-43  \\\n",
       "SpecID       ...                                                       \n",
       "201210-1-00  ...     0.023542     0.016914     0.011799     0.019152   \n",
       "201210-1-01  ...     0.015006     0.011432     0.008478     0.011922   \n",
       "201210-1-02  ...     0.000057     0.000028     0.000033     0.000033   \n",
       "201210-1-03  ...     0.001582     0.000840     0.000740     0.001059   \n",
       "201210-1-04  ...     0.026700     0.023048     0.014931     0.023701   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "210526-3-45  ...     0.566961     0.510720     0.438520     0.535863   \n",
       "210526-3-46  ...     0.559920     0.548778     0.411034     0.569511   \n",
       "210526-3-47  ...     0.448601     0.420765     0.333019     0.430109   \n",
       "210526-3-48  ...     0.546158     0.510684     0.369582     0.542970   \n",
       "210526-3-49  ...     0.508259     0.424111     0.330363     0.471578   \n",
       "\n",
       "SpecID       210526-3-44  210526-3-45  210526-3-46  210526-3-47  210526-3-48  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     0.019031     0.027628     0.024572     0.033234     0.023375   \n",
       "201210-1-01     0.011305     0.019022     0.015977     0.022697     0.015352   \n",
       "201210-1-02     0.000032     0.000095     0.000061     0.000315     0.000047   \n",
       "201210-1-03     0.001015     0.002444     0.001509     0.004226     0.001383   \n",
       "201210-1-04     0.023082     0.027218     0.028355     0.025232     0.025729   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.542634     1.000000     0.545757     0.485496     0.523684   \n",
       "210526-3-46     0.521280     0.545757     1.000000     0.460726     0.521503   \n",
       "210526-3-47     0.405293     0.485496     0.460726     1.000000     0.429772   \n",
       "210526-3-48     0.524964     0.523684     0.521503     0.429772     1.000000   \n",
       "210526-3-49     0.450585     0.469168     0.482807     0.470131     0.455532   \n",
       "\n",
       "SpecID       210526-3-49  \n",
       "SpecID                    \n",
       "201210-1-00     0.033534  \n",
       "201210-1-01     0.021558  \n",
       "201210-1-02     0.000144  \n",
       "201210-1-03     0.002989  \n",
       "201210-1-04     0.027837  \n",
       "...                  ...  \n",
       "210526-3-45     0.469168  \n",
       "210526-3-46     0.482807  \n",
       "210526-3-47     0.470131  \n",
       "210526-3-48     0.455532  \n",
       "210526-3-49     1.000000  \n",
       "\n",
       "[3045 rows x 3045 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the statuses as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example labels\n",
    "labels = df['Status']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# encoded_labels now contains numerical labels.\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "gaussian_kernel_matrix = torch.tensor(kernel_matrix)\n",
    "edge_index = torch.nonzero(gaussian_kernel_matrix).t().contiguous()\n",
    "edge_weight = gaussian_kernel_matrix[edge_index[0], edge_index[1]]\n",
    "\n",
    "# Using an identity matrix for node features\n",
    "num_nodes = gaussian_kernel_matrix.shape[0]  # Assuming square matrix\n",
    "node_features = torch.eye(num_nodes)\n",
    "\n",
    "# Converting labels to a tensor\n",
    "labels = torch.tensor(encoded_labels, dtype=torch.long)\n",
    "\n",
    "# Creating PyTorch Geometric data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_weight, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(num_features=num_nodes, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: double != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Assuming you've split your data and created a train_mask\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# For simplicity, this code snippet does not include data splitting and mask creation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[data\u001b[38;5;241m.\u001b[39mtrain_mask], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index, edge_weight\u001b[38;5;241m=\u001b[39medge_weight))\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:260\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[0;32m--> 260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "# Assuming you've split your data and created a train_mask\n",
    "# For simplicity, this code snippet does not include data splitting and mask creation\n",
    "for epoch in range(200):\n",
    "    loss = train(data)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        pred = logits.argmax(dim=1)  # Get the prediction\n",
    "        \n",
    "        # Assuming test_mask is a boolean mask of shape [num_nodes] indicating test nodes\n",
    "        test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Correct predictions\n",
    "        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Test accuracy\n",
    "        \n",
    "        return test_acc, pred[data.test_mask], data.y[data.test_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "test_acc, test_pred, test_true = test(data)\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "# Compute precision, recall, and F1 score\n",
    "precision = precision_score(test_true, test_pred, average='weighted')\n",
    "recall = recall_score(test_true, test_pred, average='weighted')\n",
    "f1 = f1_score(test_true, test_pred, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_true, test_pred)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
