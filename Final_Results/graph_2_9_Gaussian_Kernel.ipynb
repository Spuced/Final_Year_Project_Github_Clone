{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_name = os.name\n",
    "\n",
    "if os_name == 'nt':\n",
    "    password = os.getenv('NEO4J_Password')\n",
    "    neo4j_directory = os.getenv('NEO4J_Directory')\n",
    "else:\n",
    "    password = os.environ['NEO4J_Password']\n",
    "    neo4j_directory = os.environ['NEO4J_Directory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../../data/current_clean_spectrum.csv\")\n",
    "#df = pd.read_csv(\"../../data/initial_parameters.csv\")\n",
    "df = pd.read_csv(\"../../data/groupkfold_parameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalise(absorbances):\n",
    "#     max_value = np.max(absorbances)\n",
    "#     normalized_absorbances = absorbances / max_value\n",
    "#     return normalized_absorbances\n",
    "\n",
    "# df['Absorbance'] = df.groupby('SpecID')['Absorbance'].transform(lambda x: normalise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='WaveNumber', ylabel='Absorbance'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = df[df['SpecID'] == \"210526-3-06\"]\n",
    "sns.lineplot(x=\"WaveNumber\", y=\"Absorbance\", data=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>WaveNumber</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Absorbance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>293</td>\n",
       "      <td>400.22778</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.863303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>294</td>\n",
       "      <td>400.91116</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.803843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>295</td>\n",
       "      <td>401.59454</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.741884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>296</td>\n",
       "      <td>402.27789</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.677722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>297</td>\n",
       "      <td>402.96127</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.611654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239200</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2337</td>\n",
       "      <td>1797.03870</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>12.378163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239201</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2338</td>\n",
       "      <td>1797.72200</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>13.269937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239202</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2339</td>\n",
       "      <td>1798.40550</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>14.199285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239203</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2340</td>\n",
       "      <td>1799.08890</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>15.166531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239204</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2341</td>\n",
       "      <td>1799.77220</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>16.171997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6239205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SpecID   Seq  WaveNumber     SurID         Status  Absorbance\n",
       "0        201210-1-00   293   400.22778  201210-1         Normal   41.863303\n",
       "1        201210-1-00   294   400.91116  201210-1         Normal   41.803843\n",
       "2        201210-1-00   295   401.59454  201210-1         Normal   41.741884\n",
       "3        201210-1-00   296   402.27789  201210-1         Normal   41.677722\n",
       "4        201210-1-00   297   402.96127  201210-1         Normal   41.611654\n",
       "...              ...   ...         ...       ...            ...         ...\n",
       "6239200  210526-3-09  2337  1797.03870  210526-3  Hyperglycemia   12.378163\n",
       "6239201  210526-3-09  2338  1797.72200  210526-3  Hyperglycemia   13.269937\n",
       "6239202  210526-3-09  2339  1798.40550  210526-3  Hyperglycemia   14.199285\n",
       "6239203  210526-3-09  2340  1799.08890  210526-3  Hyperglycemia   15.166531\n",
       "6239204  210526-3-09  2341  1799.77220  210526-3  Hyperglycemia   16.171997\n",
       "\n",
       "[6239205 rows x 6 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wavelength_df(df, absorbance_col, status_col='Status'):\n",
    "\n",
    "    # Pivot the DataFrame to get wavelengths as columns and absorbance values\n",
    "    wavelength_df = df.pivot(index='SpecID', columns='WaveNumber', values=absorbance_col).reset_index()\n",
    "    wavelength_df.columns.name = None\n",
    "\n",
    "    # Merge with the statuses based on SpecID\n",
    "    statuses = df[['SpecID', status_col]].drop_duplicates()\n",
    "    wavelength_df = pd.merge(wavelength_df, statuses, on='SpecID')\n",
    "\n",
    "    # Set SpecID as the index\n",
    "    wavelength_df = wavelength_df.set_index('SpecID')\n",
    "\n",
    "    return wavelength_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = prepare_wavelength_df(df, 'Absorbance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Drop the 'Status' column as it is not numeric\n",
    "X = pivot_df.drop(columns=['Status'])\n",
    "\n",
    "# Calculate pairwise Euclidean distances\n",
    "distances = pdist(X.values, metric='euclidean')\n",
    "\n",
    "# Convert the condensed distances to a square matrix form\n",
    "distance_matrix = squareform(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(distances, sigma):\n",
    "    return np.exp(-distances**2 / (2 * sigma**2))\n",
    "\n",
    "# Sigma is the bandwidth parameter\n",
    "sigma = 4000 # Adjust sigma as needed\n",
    "kernel_matrix = gaussian_kernel(distance_matrix, sigma)\n",
    "\n",
    "# Convert the kernel matrix to a DataFrame\n",
    "train_kernel_df = pd.DataFrame(kernel_matrix, index=pivot_df.index, columns=pivot_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SpecID</th>\n",
       "      <th>201210-1-00</th>\n",
       "      <th>201210-1-01</th>\n",
       "      <th>201210-1-02</th>\n",
       "      <th>201210-1-03</th>\n",
       "      <th>201210-1-04</th>\n",
       "      <th>201210-1-05</th>\n",
       "      <th>201210-1-06</th>\n",
       "      <th>201210-1-07</th>\n",
       "      <th>201210-1-09</th>\n",
       "      <th>201210-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>210526-3-40</th>\n",
       "      <th>210526-3-41</th>\n",
       "      <th>210526-3-42</th>\n",
       "      <th>210526-3-43</th>\n",
       "      <th>210526-3-44</th>\n",
       "      <th>210526-3-45</th>\n",
       "      <th>210526-3-46</th>\n",
       "      <th>210526-3-47</th>\n",
       "      <th>210526-3-48</th>\n",
       "      <th>210526-3-49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960222</td>\n",
       "      <td>0.185942</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.840565</td>\n",
       "      <td>0.733965</td>\n",
       "      <td>0.732632</td>\n",
       "      <td>0.835303</td>\n",
       "      <td>0.871049</td>\n",
       "      <td>0.918058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.937744</td>\n",
       "      <td>0.928191</td>\n",
       "      <td>0.936565</td>\n",
       "      <td>0.939272</td>\n",
       "      <td>0.935973</td>\n",
       "      <td>0.934493</td>\n",
       "      <td>0.931532</td>\n",
       "      <td>0.934876</td>\n",
       "      <td>0.932618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>0.960222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232076</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>0.889082</td>\n",
       "      <td>0.796927</td>\n",
       "      <td>0.780446</td>\n",
       "      <td>0.853169</td>\n",
       "      <td>0.878050</td>\n",
       "      <td>0.900857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886819</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>0.876936</td>\n",
       "      <td>0.871103</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.862815</td>\n",
       "      <td>0.867528</td>\n",
       "      <td>0.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>0.185942</td>\n",
       "      <td>0.232076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093867</td>\n",
       "      <td>0.186239</td>\n",
       "      <td>0.179427</td>\n",
       "      <td>0.161619</td>\n",
       "      <td>0.174763</td>\n",
       "      <td>0.184361</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134140</td>\n",
       "      <td>0.135923</td>\n",
       "      <td>0.132599</td>\n",
       "      <td>0.131456</td>\n",
       "      <td>0.130767</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>0.132162</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>0.127268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>0.093867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.020385</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.010335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>0.840565</td>\n",
       "      <td>0.889082</td>\n",
       "      <td>0.186239</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944775</td>\n",
       "      <td>0.838830</td>\n",
       "      <td>0.851480</td>\n",
       "      <td>0.847944</td>\n",
       "      <td>0.857373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795307</td>\n",
       "      <td>0.797210</td>\n",
       "      <td>0.780925</td>\n",
       "      <td>0.780141</td>\n",
       "      <td>0.771758</td>\n",
       "      <td>0.765216</td>\n",
       "      <td>0.764966</td>\n",
       "      <td>0.751632</td>\n",
       "      <td>0.756838</td>\n",
       "      <td>0.760434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-45</th>\n",
       "      <td>0.935973</td>\n",
       "      <td>0.871103</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.765216</td>\n",
       "      <td>0.667469</td>\n",
       "      <td>0.703940</td>\n",
       "      <td>0.812829</td>\n",
       "      <td>0.845956</td>\n",
       "      <td>0.905551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991602</td>\n",
       "      <td>0.990718</td>\n",
       "      <td>0.989267</td>\n",
       "      <td>0.996821</td>\n",
       "      <td>0.998090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998439</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.997715</td>\n",
       "      <td>0.996144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-46</th>\n",
       "      <td>0.934493</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.764966</td>\n",
       "      <td>0.667889</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.815392</td>\n",
       "      <td>0.848672</td>\n",
       "      <td>0.908035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989657</td>\n",
       "      <td>0.989563</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>0.996412</td>\n",
       "      <td>0.997430</td>\n",
       "      <td>0.998439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.998216</td>\n",
       "      <td>0.997198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-47</th>\n",
       "      <td>0.931532</td>\n",
       "      <td>0.862815</td>\n",
       "      <td>0.132162</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.751632</td>\n",
       "      <td>0.653123</td>\n",
       "      <td>0.692555</td>\n",
       "      <td>0.804758</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.899218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984855</td>\n",
       "      <td>0.983818</td>\n",
       "      <td>0.982331</td>\n",
       "      <td>0.992953</td>\n",
       "      <td>0.995056</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997795</td>\n",
       "      <td>0.995702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-48</th>\n",
       "      <td>0.934876</td>\n",
       "      <td>0.867528</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.756838</td>\n",
       "      <td>0.657370</td>\n",
       "      <td>0.698289</td>\n",
       "      <td>0.809666</td>\n",
       "      <td>0.844295</td>\n",
       "      <td>0.904550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987466</td>\n",
       "      <td>0.986897</td>\n",
       "      <td>0.984216</td>\n",
       "      <td>0.995236</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>0.997715</td>\n",
       "      <td>0.998216</td>\n",
       "      <td>0.997795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210526-3-49</th>\n",
       "      <td>0.932618</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.127268</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.760434</td>\n",
       "      <td>0.663167</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.811044</td>\n",
       "      <td>0.842771</td>\n",
       "      <td>0.901857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988470</td>\n",
       "      <td>0.986808</td>\n",
       "      <td>0.984365</td>\n",
       "      <td>0.994886</td>\n",
       "      <td>0.996204</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>0.997198</td>\n",
       "      <td>0.995702</td>\n",
       "      <td>0.997080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 3045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SpecID       201210-1-00  201210-1-01  201210-1-02  201210-1-03  201210-1-04  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     1.000000     0.960222     0.185942     0.016573     0.840565   \n",
       "201210-1-01     0.960222     1.000000     0.232076     0.022232     0.889082   \n",
       "201210-1-02     0.185942     0.232076     1.000000     0.093867     0.186239   \n",
       "201210-1-03     0.016573     0.022232     0.093867     1.000000     0.019366   \n",
       "201210-1-04     0.840565     0.889082     0.186239     0.019366     1.000000   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.935973     0.871103     0.128275     0.010474     0.765216   \n",
       "210526-3-46     0.934493     0.869375     0.129061     0.010403     0.764966   \n",
       "210526-3-47     0.931532     0.862815     0.132162     0.010595     0.751632   \n",
       "210526-3-48     0.934876     0.867528     0.128803     0.010520     0.756838   \n",
       "210526-3-49     0.932618     0.864865     0.127268     0.010335     0.760434   \n",
       "\n",
       "SpecID       201210-1-05  201210-1-06  201210-1-07  201210-1-09  201210-1-10  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     0.733965     0.732632     0.835303     0.871049     0.918058   \n",
       "201210-1-01     0.796927     0.780446     0.853169     0.878050     0.900857   \n",
       "201210-1-02     0.179427     0.161619     0.174763     0.184361     0.170892   \n",
       "201210-1-03     0.020385     0.020779     0.020482     0.021064     0.016993   \n",
       "201210-1-04     0.944775     0.838830     0.851480     0.847944     0.857373   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.667469     0.703940     0.812829     0.845956     0.905551   \n",
       "210526-3-46     0.667889     0.705907     0.815392     0.848672     0.908035   \n",
       "210526-3-47     0.653123     0.692555     0.804758     0.839827     0.899218   \n",
       "210526-3-48     0.657370     0.698289     0.809666     0.844295     0.904550   \n",
       "210526-3-49     0.663167     0.698970     0.811044     0.842771     0.901857   \n",
       "\n",
       "SpecID       ...  210526-3-40  210526-3-41  210526-3-42  210526-3-43  \\\n",
       "SpecID       ...                                                       \n",
       "201210-1-00  ...     0.938829     0.937744     0.928191     0.936565   \n",
       "201210-1-01  ...     0.886819     0.888595     0.875283     0.877737   \n",
       "201210-1-02  ...     0.134140     0.135923     0.132599     0.131456   \n",
       "201210-1-03  ...     0.011996     0.012505     0.011572     0.011160   \n",
       "201210-1-04  ...     0.795307     0.797210     0.780925     0.780141   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "210526-3-45  ...     0.991602     0.990718     0.989267     0.996821   \n",
       "210526-3-46  ...     0.989657     0.989563     0.987226     0.996412   \n",
       "210526-3-47  ...     0.984855     0.983818     0.982331     0.992953   \n",
       "210526-3-48  ...     0.987466     0.986897     0.984216     0.995236   \n",
       "210526-3-49  ...     0.988470     0.986808     0.984365     0.994886   \n",
       "\n",
       "SpecID       210526-3-44  210526-3-45  210526-3-46  210526-3-47  210526-3-48  \\\n",
       "SpecID                                                                         \n",
       "201210-1-00     0.939272     0.935973     0.934493     0.931532     0.934876   \n",
       "201210-1-01     0.876936     0.871103     0.869375     0.862815     0.867528   \n",
       "201210-1-02     0.130767     0.128275     0.129061     0.132162     0.128803   \n",
       "201210-1-03     0.010909     0.010474     0.010403     0.010595     0.010520   \n",
       "201210-1-04     0.771758     0.765216     0.764966     0.751632     0.756838   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "210526-3-45     0.998090     1.000000     0.998439     0.996584     0.997715   \n",
       "210526-3-46     0.997430     0.998439     1.000000     0.997415     0.998216   \n",
       "210526-3-47     0.995056     0.996584     0.997415     1.000000     0.997795   \n",
       "210526-3-48     0.996960     0.997715     0.998216     0.997795     1.000000   \n",
       "210526-3-49     0.996204     0.996144     0.997198     0.995702     0.997080   \n",
       "\n",
       "SpecID       210526-3-49  \n",
       "SpecID                    \n",
       "201210-1-00     0.932618  \n",
       "201210-1-01     0.864865  \n",
       "201210-1-02     0.127268  \n",
       "201210-1-03     0.010335  \n",
       "201210-1-04     0.760434  \n",
       "...                  ...  \n",
       "210526-3-45     0.996144  \n",
       "210526-3-46     0.997198  \n",
       "210526-3-47     0.995702  \n",
       "210526-3-48     0.997080  \n",
       "210526-3-49     1.000000  \n",
       "\n",
       "[3045 rows x 3045 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_kernel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes_df = pivot_df['Status'].to_frame()\n",
    "train_nodes_df = train_nodes_df.rename_axis(\"SpecID:ID\")\n",
    "train_nodes_df = train_nodes_df.rename(columns={\"Status\": \":LABEL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes_df.to_csv(f\"{neo4j_directory}/import/nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relationship_df = train_kernel_df.reset_index()\n",
    "train_relationship_df = train_relationship_df.melt(id_vars='SpecID', var_name=':END_ID', value_name='Weight:float')\n",
    "train_relationship_df = train_relationship_df.rename(columns={'SpecID': ':START_ID'})\n",
    "train_relationship_df[':TYPE'] = 'LINK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relationship_df = train_relationship_df[train_relationship_df[\":START_ID\"] != train_relationship_df[\":END_ID\"]]\n",
    "train_relationship_df = train_relationship_df[train_relationship_df[\":START_ID\"] < train_relationship_df[\":END_ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relationship_df.to_csv(f\"{neo4j_directory}/import/relationships.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This moves the nodes and relationships files from data/current_working_graph into the DBMS import folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment this uses local paths, but the rest should be automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the admin import command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful\n",
      "b\"Neo4j version: 5.12.0\\nImporting the contents of these files into /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/data/databases/neo4j:\\nNodes:\\n  /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/import/nodes.csv\\n\\nRelationships:\\n  /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/import/relationships.csv\\n\\n\\nAvailable resources:\\n  Total machine memory: 15.47GiB\\n  Free machine memory: 4.118GiB\\n  Max heap memory : 910.5MiB\\n  Max worker threads: 8\\n  Configured max memory: 2.924GiB\\n  High parallel IO: true\\n\\nCypher type normalization is enabled (disable with --normalize-types=false):\\n  Property type of 'Weight' normalized from 'float' --> 'double' in /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/import/relationships.csv\\n\\nImport starting 2024-04-16 15:44:43.980+0100\\n  Estimated number of nodes: 3.05 k\\n  Estimated number of node properties: 3.05 k\\n  Estimated number of relationships: 4.68 M\\n  Estimated number of relationship properties: 4.68 M\\n  Estimated disk space usage: 343.7MiB\\n  Estimated required memory usage: 510.0MiB\\n\\n(1/4) Node import 2024-04-16 15:44:44.160+0100\\n  Estimated number of nodes: 3.05 k\\n  Estimated disk space usage: 4.679MiB\\n  Estimated required memory usage: 510.0MiB\\n-......... .......... .......... .......... ..........   5% \\xe2\\x88\\x8649ms\\n.......... .......... .......... .......... ..........  10% \\xe2\\x88\\x862ms\\n.......... .......... .......... .......... ..........  15% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  20% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  25% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  30% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  35% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  40% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  45% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  50% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  55% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  60% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  65% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  70% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  75% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  80% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  85% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  90% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  95% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... .......... 100% \\xe2\\x88\\x861ms\\n\\nNode import COMPLETED in 206ms\\n\\n(2/4) Relationship import 2024-04-16 15:44:44.367+0100\\n  Estimated number of relationships: 4.68 M\\n  Estimated disk space usage: 339.0MiB\\n  Estimated required memory usage: 517.6MiB\\n.......... .......... .......... .......... ..........   5% \\xe2\\x88\\x86813ms\\n.......... .......... .......... .......... ..........  10% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  15% \\xe2\\x88\\x86202ms\\n.......... .......... .......... .......... ..........  20% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  25% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  30% \\xe2\\x88\\x86202ms\\n.......... .......... .......... .......... ..........  35% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  40% \\xe2\\x88\\x86201ms\\n.......... .......... .......... .......... ..........  45% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  50% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  55% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  60% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  65% \\xe2\\x88\\x86201ms\\n.......... .......... .......... .......... ..........  70% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  75% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  80% \\xe2\\x88\\x86201ms\\n.......... .......... .......... .......... ..........  85% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  90% \\xe2\\x88\\x86623ms\\n.......... .......... .......... .......... ..........  95% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... .......... 100% \\xe2\\x88\\x860ms\\n\\nRelationship import COMPLETED in 3s 46ms\\n\\n(3/4) Relationship linking 2024-04-16 15:44:47.413+0100\\n  Estimated required memory usage: 510.0MiB\\n.......... .....-.... .......... .......... ..........   5% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  10% \\xe2\\x88\\x86401ms\\n.......... .......... .......... .......... ..........  15% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... .-........  20% \\xe2\\x88\\x86210ms\\n.......... .......... .......... .......... ..........  25% \\xe2\\x88\\x86438ms\\n.......... .......... .......... .......... ..........  30% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  35% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  40% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  45% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  50% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  55% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  60% \\xe2\\x88\\x861s 746ms\\n.......... .......... .......... .......... ..........  65% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  70% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  75% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  80% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  85% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  90% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  95% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... .......... 100% \\xe2\\x88\\x860ms\\n\\nRelationship linking COMPLETED in 4s 79ms\\n\\n(4/4) Post processing 2024-04-16 15:44:51.492+0100\\n  Estimated required memory usage: 510.0MiB\\n-......... .......... .......... .......... ..........   5% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  10% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  15% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  20% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  25% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  30% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  35% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  40% \\xe2\\x88\\x86200ms\\n.......... .......... .......... .......... ..........  45% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  50% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  55% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  60% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  65% \\xe2\\x88\\x860ms\\n.......... .......... .......... .......... ..........  70% \\xe2\\x88\\x86317ms\\n.......... .......... .......... .......... ..........  75% \\xe2\\x88\\x862ms\\n.......... .......... .......... .......... ..........  80% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  85% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  90% \\xe2\\x88\\x861ms\\n.......... .......... .......... .......... ..........  95% \\xe2\\x88\\x862ms\\n.......... .......... .......... .......... .......... 100% \\xe2\\x88\\x861ms\\n\\nPost processing COMPLETED in 1s 539ms\\n\\n\\nIMPORT DONE in 9s 357ms. \\nImported:\\n  3045 nodes\\n  4634490 relationships\\n  4637535 properties\\nPeak memory usage: 547.2MiB\\n\"\n"
     ]
    }
   ],
   "source": [
    "os_name = os.name\n",
    "\n",
    "if os_name == 'nt':\n",
    "    working_dir = f'{neo4j_directory}/bin'\n",
    "    command = 'neo4j-admin database import full --nodes=import/nodes.csv --relationships=import/relationships.csv --overwrite-destination neo4j'\n",
    "    result = subprocess.run(command, shell=True, cwd=working_dir, capture_output=True, text=True)\n",
    "else:\n",
    "    working_dir = f'{neo4j_directory}'\n",
    "    command = [\n",
    "    './bin/neo4j-admin', 'database', 'import', 'full',\n",
    "    '--nodes=import/nodes.csv',\n",
    "    '--relationships=import/relationships.csv',\n",
    "    '--overwrite-destination',  'neo4j'\n",
    "    ]\n",
    "    result = subprocess.run(command, cwd=working_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "\n",
    "# Check if the command was successful\n",
    "if result.returncode == 0:\n",
    "    print(\"Import successful\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Error during import:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restart successful\n",
      "b'Stopping Neo4j........ stopped.\\nConfiguration file validation successful (with warnings).\\nDirectories in use:\\nhome:         /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5\\nconfig:       /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/conf\\nlogs:         /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/logs\\nplugins:      /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/plugins\\nimport:       /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/import\\ndata:         /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/data\\ncertificates: /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/certificates\\nlicenses:     /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/licenses\\nrun:          /home/stang/.config/Neo4j Desktop/Application/relate-data/dbmss/dbms-f413c23c-3abd-47d4-a611-9ffc2f61bbc5/run\\nStarting Neo4j.\\nStarted neo4j (pid:298014). It is available at http://localhost:7474\\nThere may be a short delay until the server is ready.\\n'\n"
     ]
    }
   ],
   "source": [
    "if os_name != 'nt':\n",
    "    command = [\n",
    "        './bin/neo4j', 'restart'\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, cwd=neo4j_directory, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    # Check if the command was successful\n",
    "    if result.returncode == 0:\n",
    "        print(\"Restart successful\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"Error during restart:\")\n",
    "        print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and connect to the Neo4j Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"neo4j://localhost:7687\"\n",
    "username = \"neo4j\"              # Neo4J username\n",
    "#Password defined at teh top of the notebook\n",
    "\n",
    "# Create a driver instance\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Ensure you close the driver connection when your program ends\n",
    "def close_driver():\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First create the gds Graph Projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 0.8982590985183546s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 1.8802454680763283s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 3.664615991217176s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 7.130861983664424s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 19.194589648564968s (Unable to retrieve routing information)\n"
     ]
    }
   ],
   "source": [
    "def project_graph(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.graph.project(\n",
    "      'myGraph', \n",
    "      ['Normal', 'Hyperglycemia', 'Hypoglycemia'],\n",
    "      {\n",
    "        LINK: {\n",
    "          orientation: 'UNDIRECTED',\n",
    "          properties: 'Weight'\n",
    "        }\n",
    "      }\n",
    "    )\n",
    "    \"\"\"\n",
    "    tx.run(query)\n",
    "\n",
    "# Use a session to execute the graph projection\n",
    "with driver.session() as session:\n",
    "    session.execute_write(project_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the graph algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pagerank_centrality(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.pageRank.stream('myGraph', {\n",
    "        relationshipWeightProperty: 'Weight'\n",
    "    })\n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, score\n",
    "    ORDER BY score DESC, name ASC\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"score\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_degree_centrality(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.degree.stream('myGraph', {\n",
    "        relationshipWeightProperty: 'Weight'\n",
    "    })\n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, score\n",
    "    ORDER BY score DESC, name ASC\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"score\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eigenvector_centrality(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.eigenvector.stream('myGraph', {\n",
    "        relationshipWeightProperty: 'Weight'\n",
    "    })\n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, score\n",
    "    ORDER BY score DESC, name ASC\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"score\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_articlerank_centrality(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.articleRank.stream('myGraph', {\n",
    "        relationshipWeightProperty: 'Weight'\n",
    "    })\n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, score\n",
    "    ORDER BY score DESC, name ASC\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"score\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_label_propagation_algorithm(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.labelPropagation.stream('myGraph', { relationshipWeightProperty: 'Weight' })\n",
    "    YIELD nodeId, communityId AS Community\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, Community\n",
    "    ORDER BY Community, name\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"Community\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_leiden_algorithm(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.leiden.stream('myGraph', { relationshipWeightProperty: 'Weight' })\n",
    "    YIELD nodeId, communityId AS Community\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, Community\n",
    "    ORDER BY Community, name\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"Community\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_louvain_algorithm(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.louvain.stream('myGraph', { relationshipWeightProperty: 'Weight' })\n",
    "    YIELD nodeId, communityId AS Community\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, Community\n",
    "    ORDER BY Community, name\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"Community\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_node2vec_algorithm(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.node2vec.stream('myGraph', { relationshipWeightProperty: 'Weight' })\n",
    "    YIELD nodeId, embedding\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, embedding\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"embedding\"]) for record in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fastRP_algorithm(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.fastRP.stream('myGraph',\n",
    "        { relationshipWeightProperty: 'Weight',\n",
    "         randomSeed:1234,\n",
    "         embeddingDimension: 128\n",
    "        }\n",
    "    )\n",
    "    YIELD nodeId, embedding\n",
    "    RETURN gds.util.asNode(nodeId).SpecID AS name, embedding\n",
    "    \"\"\"\n",
    "    results = tx.run(query)\n",
    "    return [(record[\"name\"], record[\"embedding\"]) for record in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the algorithms and store the results in a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a session to execute the queries and retrieve the results\n",
    "with driver.session() as session:\n",
    "    pagerank_results = session.execute_read(run_pagerank_centrality)\n",
    "    degree_results = session.execute_read(run_degree_centrality)\n",
    "    eigenvector_results = session.execute_read(run_eigenvector_centrality)\n",
    "    articlerank_results = session.execute_read(run_articlerank_centrality)\n",
    "    label_propagation_results = session.execute_read(run_label_propagation_algorithm)\n",
    "    leiden_results = session.execute_read(run_leiden_algorithm)\n",
    "    louvain_results = session.execute_read(run_louvain_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_df = pd.DataFrame(pagerank_results, columns=['name', 'PageRank'])\n",
    "degree_df = pd.DataFrame(degree_results, columns=['name', 'DegreeCentrality'])\n",
    "eigenvector_df = pd.DataFrame(eigenvector_results, columns=['name', 'EigenvectorCentrality'])\n",
    "articlerank_df = pd.DataFrame(articlerank_results, columns=['name', 'ArticleRank'])\n",
    "label_propagation_df = pd.DataFrame(label_propagation_results, columns=['name', 'LabelPropagation'])\n",
    "leiden_df = pd.DataFrame(leiden_results, columns=['name', 'Leiden'])\n",
    "louvain_df = pd.DataFrame(louvain_results, columns=['name', 'Louvain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pagerank_df\n",
    "for df in [degree_df, eigenvector_df, articlerank_df, leiden_df, louvain_df]:\n",
    "    merged_df = pd.merge(merged_df, df, on=['name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>DegreeCentrality</th>\n",
       "      <th>EigenvectorCentrality</th>\n",
       "      <th>ArticleRank</th>\n",
       "      <th>Leiden</th>\n",
       "      <th>Louvain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210504-1-29</td>\n",
       "      <td>8.063099</td>\n",
       "      <td>2.118526e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>54</td>\n",
       "      <td>2394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210505-1-11</td>\n",
       "      <td>6.324768</td>\n",
       "      <td>2.060467e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150001</td>\n",
       "      <td>147</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210510-2-43</td>\n",
       "      <td>5.510720</td>\n",
       "      <td>1.276318e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150005</td>\n",
       "      <td>21</td>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210505-1-10</td>\n",
       "      <td>5.496797</td>\n",
       "      <td>2.045747e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150001</td>\n",
       "      <td>147</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210504-1-33</td>\n",
       "      <td>5.463643</td>\n",
       "      <td>9.491556e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>8</td>\n",
       "      <td>2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>210303-2-26</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3.713241e-46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>210304-2-02</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3.942857e-144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>223</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>210324-2-34</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>5.486276e-41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>210407-1-03</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>4.587602e-42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>35</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>210407-1-32</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>5.526831e-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SpecID  PageRank  DegreeCentrality  EigenvectorCentrality  \\\n",
       "0     210504-1-29  8.063099      2.118526e-10                    0.0   \n",
       "1     210505-1-11  6.324768      2.060467e-02                    0.0   \n",
       "2     210510-2-43  5.510720      1.276318e-01                    0.0   \n",
       "3     210505-1-10  5.496797      2.045747e-02                    0.0   \n",
       "4     210504-1-33  5.463643      9.491556e-08                    0.0   \n",
       "...           ...       ...               ...                    ...   \n",
       "3040  210303-2-26  0.150000      3.713241e-46                    0.0   \n",
       "3041  210304-2-02  0.150000     3.942857e-144                    0.0   \n",
       "3042  210324-2-34  0.150000      5.486276e-41                    0.0   \n",
       "3043  210407-1-03  0.150000      4.587602e-42                    0.0   \n",
       "3044  210407-1-32  0.150000      5.526831e-29                    0.0   \n",
       "\n",
       "      ArticleRank  Leiden  Louvain  \n",
       "0        0.150000      54     2394  \n",
       "1        0.150001     147     2525  \n",
       "2        0.150005      21     2658  \n",
       "3        0.150001     147     2525  \n",
       "4        0.150000       8     2527  \n",
       "...           ...     ...      ...  \n",
       "3040     0.150000       1     1381  \n",
       "3041     0.150000     223      336  \n",
       "3042     0.150000       6      477  \n",
       "3043     0.150000      35     1701  \n",
       "3044     0.150000       6     1760  \n",
       "\n",
       "[3045 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_df.rename(columns={'name' : 'SpecID'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_118</th>\n",
       "      <th>embedding_119</th>\n",
       "      <th>embedding_120</th>\n",
       "      <th>embedding_121</th>\n",
       "      <th>embedding_122</th>\n",
       "      <th>embedding_123</th>\n",
       "      <th>embedding_124</th>\n",
       "      <th>embedding_125</th>\n",
       "      <th>embedding_126</th>\n",
       "      <th>embedding_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>-0.126921</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.313777</td>\n",
       "      <td>0.217399</td>\n",
       "      <td>0.141151</td>\n",
       "      <td>-0.116146</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>-0.075381</td>\n",
       "      <td>0.028979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197569</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>-0.104828</td>\n",
       "      <td>0.108536</td>\n",
       "      <td>0.310620</td>\n",
       "      <td>-0.044107</td>\n",
       "      <td>0.028253</td>\n",
       "      <td>-0.101956</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>-0.022226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-01</td>\n",
       "      <td>-0.124933</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>0.312783</td>\n",
       "      <td>0.214692</td>\n",
       "      <td>0.141758</td>\n",
       "      <td>-0.115651</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>-0.077285</td>\n",
       "      <td>0.030259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197404</td>\n",
       "      <td>-0.007553</td>\n",
       "      <td>-0.102692</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.310848</td>\n",
       "      <td>-0.044121</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>-0.103600</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>-0.023261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-02</td>\n",
       "      <td>-0.121030</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>0.311113</td>\n",
       "      <td>0.209621</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>-0.114374</td>\n",
       "      <td>0.036854</td>\n",
       "      <td>-0.080790</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197173</td>\n",
       "      <td>-0.008203</td>\n",
       "      <td>-0.098837</td>\n",
       "      <td>0.111467</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>-0.044168</td>\n",
       "      <td>0.024581</td>\n",
       "      <td>-0.106579</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-0.024959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-03</td>\n",
       "      <td>-0.100998</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.301661</td>\n",
       "      <td>0.183001</td>\n",
       "      <td>0.148147</td>\n",
       "      <td>-0.110117</td>\n",
       "      <td>0.034071</td>\n",
       "      <td>-0.099429</td>\n",
       "      <td>0.046803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195584</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.080722</td>\n",
       "      <td>0.120950</td>\n",
       "      <td>0.312045</td>\n",
       "      <td>-0.049881</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>-0.125008</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>-0.031517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-04</td>\n",
       "      <td>-0.122028</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.311272</td>\n",
       "      <td>0.210577</td>\n",
       "      <td>0.142558</td>\n",
       "      <td>-0.115046</td>\n",
       "      <td>0.036947</td>\n",
       "      <td>-0.080157</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197155</td>\n",
       "      <td>-0.007748</td>\n",
       "      <td>-0.099646</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.311228</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>-0.106179</td>\n",
       "      <td>-0.002234</td>\n",
       "      <td>-0.024691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SpecID  embedding_0  embedding_1  embedding_2  embedding_3  \\\n",
       "0  201210-1-00    -0.126921     0.029483     0.313777     0.217399   \n",
       "1  201210-1-01    -0.124933     0.028509     0.312783     0.214692   \n",
       "2  201210-1-02    -0.121030     0.026722     0.311113     0.209621   \n",
       "3  201210-1-03    -0.100998     0.012337     0.301661     0.183001   \n",
       "4  201210-1-04    -0.122028     0.026827     0.311272     0.210577   \n",
       "\n",
       "   embedding_4  embedding_5  embedding_6  embedding_7  embedding_8  ...  \\\n",
       "0     0.141151    -0.116146     0.036769    -0.075381     0.028979  ...   \n",
       "1     0.141758    -0.115651     0.036883    -0.077285     0.030259  ...   \n",
       "2     0.142960    -0.114374     0.036854    -0.080790     0.032723  ...   \n",
       "3     0.148147    -0.110117     0.034071    -0.099429     0.046803  ...   \n",
       "4     0.142558    -0.115046     0.036947    -0.080157     0.032158  ...   \n",
       "\n",
       "   embedding_118  embedding_119  embedding_120  embedding_121  embedding_122  \\\n",
       "0      -0.197569      -0.007299      -0.104828       0.108536       0.310620   \n",
       "1      -0.197404      -0.007553      -0.102692       0.109560       0.310848   \n",
       "2      -0.197173      -0.008203      -0.098837       0.111467       0.311111   \n",
       "3      -0.195584      -0.005931      -0.080722       0.120950       0.312045   \n",
       "4      -0.197155      -0.007748      -0.099646       0.111094       0.311228   \n",
       "\n",
       "   embedding_123  embedding_124  embedding_125  embedding_126  embedding_127  \n",
       "0      -0.044107       0.028253      -0.101956      -0.004545      -0.022226  \n",
       "1      -0.044121       0.027004      -0.103600      -0.003526      -0.023261  \n",
       "2      -0.044168       0.024581      -0.106579      -0.001555      -0.024959  \n",
       "3      -0.049881       0.012532      -0.125008       0.004476      -0.031517  \n",
       "4      -0.044407       0.025240      -0.106179      -0.002234      -0.024691  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with driver.session() as session:\n",
    "    fastRP_results = session.execute_read(run_fastRP_algorithm)\n",
    "\n",
    "fastRP_df = pd.DataFrame(fastRP_results, columns=['SpecID', 'embeddings'])\n",
    "\n",
    "# Expand the embeddings list into separate columns\n",
    "embeddings_df = pd.DataFrame(fastRP_df['embeddings'].tolist(), index=fastRP_df.index)\n",
    "\n",
    "# Optionally, rename the new columns\n",
    "embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "# Join the new embeddings columns to the original DataFrame\n",
    "fastRP_df = pd.concat([fastRP_df.drop(['embeddings'], axis=1), embeddings_df], axis=1)\n",
    "fastRP_df.to_csv('../../data/fastRP_embeddings.csv', index=False)\n",
    "fastRP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.read_csv(f\"{neo4j_directory}/import/nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.merge(df, status_df, left_on=\"SpecID\", right_on=\"SpecID:ID\", how=\"inner\")\n",
    "graph_df.drop(columns=[\"SpecID:ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_graph_df = pd.merge(fastRP_df, status_df, left_on=\"SpecID\", right_on=\"SpecID:ID\", how=\"inner\")\n",
    "fast_graph_df.drop(columns=[\"SpecID:ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>DegreeCentrality</th>\n",
       "      <th>EigenvectorCentrality</th>\n",
       "      <th>ArticleRank</th>\n",
       "      <th>Leiden</th>\n",
       "      <th>Louvain</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210504-1-29</td>\n",
       "      <td>8.063099</td>\n",
       "      <td>2.118526e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>54</td>\n",
       "      <td>2394</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210505-1-11</td>\n",
       "      <td>6.324768</td>\n",
       "      <td>2.060467e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150001</td>\n",
       "      <td>147</td>\n",
       "      <td>2525</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210510-2-43</td>\n",
       "      <td>5.510720</td>\n",
       "      <td>1.276318e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150005</td>\n",
       "      <td>21</td>\n",
       "      <td>2658</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210505-1-10</td>\n",
       "      <td>5.496797</td>\n",
       "      <td>2.045747e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150001</td>\n",
       "      <td>147</td>\n",
       "      <td>2525</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210504-1-33</td>\n",
       "      <td>5.463643</td>\n",
       "      <td>9.491556e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>8</td>\n",
       "      <td>2527</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>210303-2-26</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3.713241e-46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>1381</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>210304-2-02</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>3.942857e-144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>223</td>\n",
       "      <td>336</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>210324-2-34</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>5.486276e-41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>477</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>210407-1-03</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>4.587602e-42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>35</td>\n",
       "      <td>1701</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>210407-1-32</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>5.526831e-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>1760</td>\n",
       "      <td>Hypoglycemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SpecID  PageRank  DegreeCentrality  EigenvectorCentrality  \\\n",
       "0     210504-1-29  8.063099      2.118526e-10                    0.0   \n",
       "1     210505-1-11  6.324768      2.060467e-02                    0.0   \n",
       "2     210510-2-43  5.510720      1.276318e-01                    0.0   \n",
       "3     210505-1-10  5.496797      2.045747e-02                    0.0   \n",
       "4     210504-1-33  5.463643      9.491556e-08                    0.0   \n",
       "...           ...       ...               ...                    ...   \n",
       "3040  210303-2-26  0.150000      3.713241e-46                    0.0   \n",
       "3041  210304-2-02  0.150000     3.942857e-144                    0.0   \n",
       "3042  210324-2-34  0.150000      5.486276e-41                    0.0   \n",
       "3043  210407-1-03  0.150000      4.587602e-42                    0.0   \n",
       "3044  210407-1-32  0.150000      5.526831e-29                    0.0   \n",
       "\n",
       "      ArticleRank  Leiden  Louvain         :LABEL  \n",
       "0        0.150000      54     2394   Hypoglycemia  \n",
       "1        0.150001     147     2525   Hypoglycemia  \n",
       "2        0.150005      21     2658  Hyperglycemia  \n",
       "3        0.150001     147     2525   Hypoglycemia  \n",
       "4        0.150000       8     2527   Hypoglycemia  \n",
       "...           ...     ...      ...            ...  \n",
       "3040     0.150000       1     1381         Normal  \n",
       "3041     0.150000     223      336   Hypoglycemia  \n",
       "3042     0.150000       6      477         Normal  \n",
       "3043     0.150000      35     1701   Hypoglycemia  \n",
       "3044     0.150000       6     1760   Hypoglycemia  \n",
       "\n",
       "[3045 rows x 8 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df.rename(columns={\":LABEL\":\"Status\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_graph_df.rename(columns={\":LABEL\":\"Status\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Cross-Validation Accuracy: 0.4778 +/- 0.0298\n",
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.4798 +/- 0.0211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "X = graph_df.drop(['SpecID', 'Status'], axis=1)\n",
    "y = graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Cross-Validation Accuracy: 0.4851 +/- 0.0323\n",
      "RandomForestClassifier Cross-Validation Precision: 0.4842 +/- 0.0316\n",
      "RandomForestClassifier Cross-Validation Recall: 0.4834 +/- 0.0326\n",
      "RandomForestClassifier Cross-Validation F1-Score: 0.4823 +/- 0.0329\n",
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.4798 +/- 0.0301\n",
      "ExtraTreesClassifier Cross-Validation Precision: 0.4785 +/- 0.0309\n",
      "ExtraTreesClassifier Cross-Validation Recall: 0.4777 +/- 0.0309\n",
      "ExtraTreesClassifier Cross-Validation F1-Score: 0.4769 +/- 0.0313\n",
      "SVC Cross-Validation Accuracy: 0.4509 +/- 0.0278\n",
      "SVC Cross-Validation Precision: 0.5699 +/- 0.0471\n",
      "SVC Cross-Validation Recall: 0.4348 +/- 0.0274\n",
      "SVC Cross-Validation F1-Score: 0.3964 +/- 0.0281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "X = graph_df.drop(['Status', 'SpecID'], axis=1)\n",
    "y = graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et, svc]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores['test_accuracy']):.4f} +/- {np.std(scores['test_accuracy']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Precision: {np.mean(scores['test_precision_macro']):.4f} +/- {np.std(scores['test_precision_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Recall: {np.mean(scores['test_recall_macro']):.4f} +/- {np.std(scores['test_recall_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation F1-Score: {np.mean(scores['test_f1_macro']):.4f} +/- {np.std(scores['test_f1_macro']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df['SurID'] = graph_df['SpecID'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Cross-Validation Accuracy: 0.3624 +/- 0.0566\n",
      "RandomForestClassifier Cross-Validation Precision: 0.3651 +/- 0.0553\n",
      "RandomForestClassifier Cross-Validation Recall: 0.3667 +/- 0.0812\n",
      "RandomForestClassifier Cross-Validation F1-Score: 0.3478 +/- 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.3618 +/- 0.0587\n",
      "ExtraTreesClassifier Cross-Validation Precision: 0.3626 +/- 0.0529\n",
      "ExtraTreesClassifier Cross-Validation Recall: 0.3633 +/- 0.0800\n",
      "ExtraTreesClassifier Cross-Validation F1-Score: 0.3460 +/- 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Cross-Validation Accuracy: 0.3728 +/- 0.1299\n",
      "SVC Cross-Validation Precision: 0.4375 +/- 0.1941\n",
      "SVC Cross-Validation Recall: 0.3840 +/- 0.1712\n",
      "SVC Cross-Validation F1-Score: 0.3305 +/- 0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "groups = graph_df['SurID']\n",
    "X = graph_df.drop(['Status', 'SpecID', 'SurID'], axis=1)\n",
    "y = graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et, svc]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_validate(clf, X, y, groups=groups, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores['test_accuracy']):.4f} +/- {np.std(scores['test_accuracy']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Precision: {np.mean(scores['test_precision_macro']):.4f} +/- {np.std(scores['test_precision_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Recall: {np.mean(scores['test_recall_macro']):.4f} +/- {np.std(scores['test_recall_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation F1-Score: {np.mean(scores['test_f1_macro']):.4f} +/- {np.std(scores['test_f1_macro']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Random Forest model\n",
    "graph_rf_model = RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "graph_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Extra Trees model\n",
    "graph_et_model = ExtraTreesClassifier(n_estimators=100, random_state=1234)\n",
    "graph_et_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = graph_rf_model.predict(X_test)\n",
    "et_predictions = graph_et_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "et_accuracy = accuracy_score(y_test, et_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_pred):\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy}\\n\")\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Show the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(model, X):\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = model.feature_importances_\n",
    "\n",
    "    # Creating a DataFrame to display feature importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "    # Sorting the DataFrame by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Show the top 10 most important features\n",
    "    top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "    return top_10_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5205254515599343\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.50      0.51      0.51       175\n",
      " Hypoglycemia       0.52      0.53      0.52       220\n",
      "       Normal       0.54      0.51      0.53       214\n",
      "\n",
      "     accuracy                           0.52       609\n",
      "    macro avg       0.52      0.52      0.52       609\n",
      " weighted avg       0.52      0.52      0.52       609\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 90  49  36]\n",
      " [ 47 117  56]\n",
      " [ 43  61 110]]\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5139573070607554\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.48      0.48      0.48       175\n",
      " Hypoglycemia       0.51      0.51      0.51       220\n",
      "       Normal       0.55      0.55      0.55       214\n",
      "\n",
      "     accuracy                           0.51       609\n",
      "    macro avg       0.51      0.51      0.51       609\n",
      " weighted avg       0.51      0.51      0.51       609\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 84  48  43]\n",
      " [ 54 112  54]\n",
      " [ 38  59 117]]\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_test, et_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>0.344540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DegreeCentrality</td>\n",
       "      <td>0.286502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArticleRank</td>\n",
       "      <td>0.270183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.051541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.047234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EigenvectorCentrality</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "0               PageRank    0.344540\n",
       "1       DegreeCentrality    0.286502\n",
       "3            ArticleRank    0.270183\n",
       "5                Louvain    0.051541\n",
       "4                 Leiden    0.047234\n",
       "2  EigenvectorCentrality    0.000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_importances(graph_rf_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PageRank</td>\n",
       "      <td>0.334586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DegreeCentrality</td>\n",
       "      <td>0.300108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArticleRank</td>\n",
       "      <td>0.276871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Louvain</td>\n",
       "      <td>0.048326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leiden</td>\n",
       "      <td>0.040109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EigenvectorCentrality</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "0               PageRank    0.334586\n",
       "1       DegreeCentrality    0.300108\n",
       "3            ArticleRank    0.276871\n",
       "5                Louvain    0.048326\n",
       "4                 Leiden    0.040109\n",
       "2  EigenvectorCentrality    0.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_importances(graph_et_model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastRp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_119</th>\n",
       "      <th>embedding_120</th>\n",
       "      <th>embedding_121</th>\n",
       "      <th>embedding_122</th>\n",
       "      <th>embedding_123</th>\n",
       "      <th>embedding_124</th>\n",
       "      <th>embedding_125</th>\n",
       "      <th>embedding_126</th>\n",
       "      <th>embedding_127</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>-0.126856</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.312416</td>\n",
       "      <td>0.223328</td>\n",
       "      <td>0.128330</td>\n",
       "      <td>-0.112877</td>\n",
       "      <td>0.034097</td>\n",
       "      <td>-0.075095</td>\n",
       "      <td>0.027202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>-0.104161</td>\n",
       "      <td>0.107659</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>-0.055208</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>-0.101856</td>\n",
       "      <td>-0.005557</td>\n",
       "      <td>-0.018172</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-01</td>\n",
       "      <td>-0.125399</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.311529</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>-0.112619</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>-0.076966</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008172</td>\n",
       "      <td>-0.102161</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.305113</td>\n",
       "      <td>-0.055215</td>\n",
       "      <td>0.042228</td>\n",
       "      <td>-0.103425</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-02</td>\n",
       "      <td>-0.123358</td>\n",
       "      <td>0.039899</td>\n",
       "      <td>0.310530</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.129119</td>\n",
       "      <td>-0.112073</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>-0.079315</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008845</td>\n",
       "      <td>-0.099716</td>\n",
       "      <td>0.110159</td>\n",
       "      <td>0.305353</td>\n",
       "      <td>-0.055236</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>-0.105426</td>\n",
       "      <td>-0.003343</td>\n",
       "      <td>-0.020210</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-03</td>\n",
       "      <td>-0.110808</td>\n",
       "      <td>0.030174</td>\n",
       "      <td>0.303462</td>\n",
       "      <td>0.195779</td>\n",
       "      <td>0.132131</td>\n",
       "      <td>-0.110179</td>\n",
       "      <td>0.033030</td>\n",
       "      <td>-0.095497</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009282</td>\n",
       "      <td>-0.084771</td>\n",
       "      <td>0.119222</td>\n",
       "      <td>0.307137</td>\n",
       "      <td>-0.058461</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>-0.119889</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>-0.026324</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-04</td>\n",
       "      <td>-0.121557</td>\n",
       "      <td>0.038382</td>\n",
       "      <td>0.309043</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.129492</td>\n",
       "      <td>-0.112088</td>\n",
       "      <td>0.034283</td>\n",
       "      <td>-0.082122</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008898</td>\n",
       "      <td>-0.097029</td>\n",
       "      <td>0.111685</td>\n",
       "      <td>0.306225</td>\n",
       "      <td>-0.055691</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>-0.107878</td>\n",
       "      <td>-0.002353</td>\n",
       "      <td>-0.021484</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>210526-3-45</td>\n",
       "      <td>-0.127237</td>\n",
       "      <td>0.041604</td>\n",
       "      <td>0.312535</td>\n",
       "      <td>0.223764</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>-0.113017</td>\n",
       "      <td>0.034144</td>\n",
       "      <td>-0.074790</td>\n",
       "      <td>0.027008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007660</td>\n",
       "      <td>-0.104495</td>\n",
       "      <td>0.107413</td>\n",
       "      <td>0.304829</td>\n",
       "      <td>-0.055150</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>-0.101533</td>\n",
       "      <td>-0.005722</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>210526-3-46</td>\n",
       "      <td>-0.127292</td>\n",
       "      <td>0.041628</td>\n",
       "      <td>0.312574</td>\n",
       "      <td>0.223859</td>\n",
       "      <td>0.128286</td>\n",
       "      <td>-0.113043</td>\n",
       "      <td>0.034124</td>\n",
       "      <td>-0.074720</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007644</td>\n",
       "      <td>-0.104575</td>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.304797</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>0.043247</td>\n",
       "      <td>-0.101500</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>210526-3-47</td>\n",
       "      <td>-0.127523</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.312714</td>\n",
       "      <td>0.224251</td>\n",
       "      <td>0.128193</td>\n",
       "      <td>-0.113105</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>-0.074430</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007594</td>\n",
       "      <td>-0.104905</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>0.304710</td>\n",
       "      <td>-0.055229</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>-0.101289</td>\n",
       "      <td>-0.005944</td>\n",
       "      <td>-0.017803</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>210526-3-48</td>\n",
       "      <td>-0.127487</td>\n",
       "      <td>0.041724</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.224208</td>\n",
       "      <td>0.128208</td>\n",
       "      <td>-0.113091</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>-0.074463</td>\n",
       "      <td>0.026809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.104866</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>0.304716</td>\n",
       "      <td>-0.055224</td>\n",
       "      <td>0.043368</td>\n",
       "      <td>-0.101308</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.017824</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>210526-3-49</td>\n",
       "      <td>-0.127388</td>\n",
       "      <td>0.041673</td>\n",
       "      <td>0.312632</td>\n",
       "      <td>0.224028</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>-0.113064</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074593</td>\n",
       "      <td>0.026890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007627</td>\n",
       "      <td>-0.104720</td>\n",
       "      <td>0.107328</td>\n",
       "      <td>0.304756</td>\n",
       "      <td>-0.055210</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>-0.101408</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>-0.017905</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SpecID  embedding_0  embedding_1  embedding_2  embedding_3  \\\n",
       "0     201210-1-00    -0.126856     0.041533     0.312416     0.223328   \n",
       "1     201210-1-01    -0.125399     0.040796     0.311529     0.220783   \n",
       "2     201210-1-02    -0.123358     0.039899     0.310530     0.217500   \n",
       "3     201210-1-03    -0.110808     0.030174     0.303462     0.195779   \n",
       "4     201210-1-04    -0.121557     0.038382     0.309043     0.213698   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3040  210526-3-45    -0.127237     0.041604     0.312535     0.223764   \n",
       "3041  210526-3-46    -0.127292     0.041628     0.312574     0.223859   \n",
       "3042  210526-3-47    -0.127523     0.041741     0.312714     0.224251   \n",
       "3043  210526-3-48    -0.127487     0.041724     0.312700     0.224208   \n",
       "3044  210526-3-49    -0.127388     0.041673     0.312632     0.224028   \n",
       "\n",
       "      embedding_4  embedding_5  embedding_6  embedding_7  embedding_8  ...  \\\n",
       "0        0.128330    -0.112877     0.034097    -0.075095     0.027202  ...   \n",
       "1        0.128676    -0.112619     0.034209    -0.076966     0.028316  ...   \n",
       "2        0.129119    -0.112073     0.034152    -0.079315     0.029759  ...   \n",
       "3        0.132131    -0.110179     0.033030    -0.095497     0.039937  ...   \n",
       "4        0.129492    -0.112088     0.034283    -0.082122     0.031278  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "3040     0.128329    -0.113017     0.034144    -0.074790     0.027008  ...   \n",
       "3041     0.128286    -0.113043     0.034124    -0.074720     0.026967  ...   \n",
       "3042     0.128193    -0.113105     0.034084    -0.074430     0.026786  ...   \n",
       "3043     0.128208    -0.113091     0.034084    -0.074463     0.026809  ...   \n",
       "3044     0.128242    -0.113064     0.034098    -0.074593     0.026890  ...   \n",
       "\n",
       "      embedding_119  embedding_120  embedding_121  embedding_122  \\\n",
       "0         -0.007818      -0.104161       0.107659       0.304749   \n",
       "1         -0.008172      -0.102161       0.108725       0.305113   \n",
       "2         -0.008845      -0.099716       0.110159       0.305353   \n",
       "3         -0.009282      -0.084771       0.119222       0.307137   \n",
       "4         -0.008898      -0.097029       0.111685       0.306225   \n",
       "...             ...            ...            ...            ...   \n",
       "3040      -0.007660      -0.104495       0.107413       0.304829   \n",
       "3041      -0.007644      -0.104575       0.107379       0.304797   \n",
       "3042      -0.007594      -0.104905       0.107231       0.304710   \n",
       "3043      -0.007599      -0.104866       0.107252       0.304716   \n",
       "3044      -0.007627      -0.104720       0.107328       0.304756   \n",
       "\n",
       "      embedding_123  embedding_124  embedding_125  embedding_126  \\\n",
       "0         -0.055208       0.043022      -0.101856      -0.005557   \n",
       "1         -0.055215       0.042228      -0.103425      -0.004603   \n",
       "2         -0.055236       0.041107      -0.105426      -0.003343   \n",
       "3         -0.058461       0.033479      -0.119889       0.002414   \n",
       "4         -0.055691       0.040199      -0.107878      -0.002353   \n",
       "...             ...            ...            ...            ...   \n",
       "3040      -0.055150       0.043200      -0.101533      -0.005722   \n",
       "3041      -0.055179       0.043247      -0.101500      -0.005773   \n",
       "3042      -0.055229       0.043399      -0.101289      -0.005944   \n",
       "3043      -0.055224       0.043368      -0.101308      -0.005926   \n",
       "3044      -0.055210       0.043305      -0.101408      -0.005841   \n",
       "\n",
       "      embedding_127         Status  \n",
       "0         -0.018172         Normal  \n",
       "1         -0.019147         Normal  \n",
       "2         -0.020210         Normal  \n",
       "3         -0.026324         Normal  \n",
       "4         -0.021484         Normal  \n",
       "...             ...            ...  \n",
       "3040      -0.018050  Hyperglycemia  \n",
       "3041      -0.017992  Hyperglycemia  \n",
       "3042      -0.017803  Hyperglycemia  \n",
       "3043      -0.017824  Hyperglycemia  \n",
       "3044      -0.017905  Hyperglycemia  \n",
       "\n",
       "[3045 rows x 130 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(random_state=1234)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(random_state=1234)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(random_state=1234)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Drop the SpecID column\n",
    "X_train = fast_graph_df.drop(columns=['SpecID', 'Status'])\n",
    "\n",
    "# Target variable\n",
    "y_train= fast_graph_df['Status']\n",
    "\n",
    "# Random Forest model\n",
    "fastrp_rf_model = RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "fastrp_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Extra Trees model\n",
    "fastrp_et_model = ExtraTreesClassifier(n_estimators=100, random_state=1234)\n",
    "fastrp_et_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4786885245901639\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.43      0.44      0.43        91\n",
      " Hypoglycemia       0.51      0.46      0.48       107\n",
      "       Normal       0.50      0.53      0.52       107\n",
      "\n",
      "     accuracy                           0.48       305\n",
      "    macro avg       0.48      0.48      0.48       305\n",
      " weighted avg       0.48      0.48      0.48       305\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40 24 27]\n",
      " [28 49 30]\n",
      " [26 24 57]]\n",
      "Overall Accuracy: 0.5278688524590164\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.52      0.46      0.49        91\n",
      " Hypoglycemia       0.53      0.58      0.56       107\n",
      "       Normal       0.53      0.53      0.53       107\n",
      "\n",
      "     accuracy                           0.53       305\n",
      "    macro avg       0.53      0.52      0.52       305\n",
      " weighted avg       0.53      0.53      0.53       305\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42 22 27]\n",
      " [21 62 24]\n",
      " [18 32 57]]\n",
      "Overall Accuracy: 0.4786885245901639\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.47      0.47      0.47        91\n",
      " Hypoglycemia       0.47      0.44      0.45       107\n",
      "       Normal       0.50      0.52      0.51       107\n",
      "\n",
      "     accuracy                           0.48       305\n",
      "    macro avg       0.48      0.48      0.48       305\n",
      " weighted avg       0.48      0.48      0.48       305\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43 27 21]\n",
      " [24 47 36]\n",
      " [25 26 56]]\n",
      "Overall Accuracy: 0.4557377049180328\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.47      0.45      0.46        91\n",
      " Hypoglycemia       0.46      0.50      0.48       107\n",
      "       Normal       0.44      0.42      0.43       107\n",
      "\n",
      "     accuracy                           0.46       305\n",
      "    macro avg       0.46      0.46      0.46       305\n",
      " weighted avg       0.46      0.46      0.46       305\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41 22 28]\n",
      " [25 53 29]\n",
      " [22 40 45]]\n",
      "Overall Accuracy: 0.4885245901639344\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.48      0.48      0.48        91\n",
      " Hypoglycemia       0.47      0.47      0.47       107\n",
      "       Normal       0.51      0.51      0.51       107\n",
      "\n",
      "     accuracy                           0.49       305\n",
      "    macro avg       0.49      0.49      0.49       305\n",
      " weighted avg       0.49      0.49      0.49       305\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44 31 16]\n",
      " [21 50 36]\n",
      " [26 26 55]]\n",
      "Overall Accuracy: 0.5296052631578947\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.54      0.49      0.51        92\n",
      " Hypoglycemia       0.46      0.47      0.47       106\n",
      "       Normal       0.59      0.62      0.61       106\n",
      "\n",
      "     accuracy                           0.53       304\n",
      "    macro avg       0.53      0.53      0.53       304\n",
      " weighted avg       0.53      0.53      0.53       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45 31 16]\n",
      " [26 50 30]\n",
      " [13 27 66]]\n",
      "Overall Accuracy: 0.5098684210526315\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.49      0.54      0.51        92\n",
      " Hypoglycemia       0.52      0.47      0.49       106\n",
      "       Normal       0.53      0.52      0.52       106\n",
      "\n",
      "     accuracy                           0.51       304\n",
      "    macro avg       0.51      0.51      0.51       304\n",
      " weighted avg       0.51      0.51      0.51       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[50 21 21]\n",
      " [28 50 28]\n",
      " [25 26 55]]\n",
      "Overall Accuracy: 0.5131578947368421\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.53      0.50      0.51        92\n",
      " Hypoglycemia       0.50      0.51      0.50       106\n",
      "       Normal       0.51      0.53      0.52       106\n",
      "\n",
      "     accuracy                           0.51       304\n",
      "    macro avg       0.51      0.51      0.51       304\n",
      " weighted avg       0.51      0.51      0.51       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46 24 22]\n",
      " [21 54 31]\n",
      " [20 30 56]]\n",
      "Overall Accuracy: 0.4473684210526316\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.43      0.41      0.42        92\n",
      " Hypoglycemia       0.43      0.39      0.41       106\n",
      "       Normal       0.47      0.54      0.50       106\n",
      "\n",
      "     accuracy                           0.45       304\n",
      "    macro avg       0.44      0.45      0.44       304\n",
      " weighted avg       0.45      0.45      0.45       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38 27 27]\n",
      " [28 41 37]\n",
      " [22 27 57]]\n",
      "Overall Accuracy: 0.45723684210526316\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Hyperglycemia       0.41      0.36      0.38        92\n",
      " Hypoglycemia       0.45      0.54      0.49       106\n",
      "       Normal       0.51      0.46      0.48       106\n",
      "\n",
      "     accuracy                           0.46       304\n",
      "    macro avg       0.46      0.45      0.45       304\n",
      " weighted avg       0.46      0.46      0.46       304\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33 34 25]\n",
      " [26 57 23]\n",
      " [21 36 49]]\n",
      "Accuracy: 0.4887 +/- 0.0287\n",
      "Precision: 0.4886 +/- 0.0290\n",
      "Recall: 0.4887 +/- 0.0287\n",
      "F1-Score: 0.4879 +/- 0.0291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "\n",
    "# Performing 10-fold cross-validation for the classifier\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    et.fit(X_train, y_train)\n",
    "    y_pred = et.predict(X_test)\n",
    "    \n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    calculate_metrics(y_test, y_pred)\n",
    "\n",
    "# Displaying the results\n",
    "print(f'Accuracy: {np.mean(accuracy_scores):.4f} +/- {np.std(accuracy_scores):.4f}')\n",
    "print(f'Precision: {np.mean(precision_scores):.4f} +/- {np.std(precision_scores):.4f}')\n",
    "print(f'Recall: {np.mean(recall_scores):.4f} +/- {np.std(recall_scores):.4f}')\n",
    "print(f'F1-Score: {np.mean(f1_scores):.4f} +/- {np.std(f1_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Cross-Validation Accuracy: 0.7409 +/- 0.0153\n",
      "RandomForestClassifier Cross-Validation Precision: 0.7400 +/- 0.0151\n",
      "RandomForestClassifier Cross-Validation Recall: 0.7404 +/- 0.0147\n",
      "RandomForestClassifier Cross-Validation F1-Score: 0.7387 +/- 0.0148\n",
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.7218 +/- 0.0201\n",
      "ExtraTreesClassifier Cross-Validation Precision: 0.7215 +/- 0.0202\n",
      "ExtraTreesClassifier Cross-Validation Recall: 0.7214 +/- 0.0198\n",
      "ExtraTreesClassifier Cross-Validation F1-Score: 0.7201 +/- 0.0201\n",
      "SVC Cross-Validation Accuracy: 0.4742 +/- 0.0301\n",
      "SVC Cross-Validation Precision: 0.5389 +/- 0.0333\n",
      "SVC Cross-Validation Recall: 0.4659 +/- 0.0248\n",
      "SVC Cross-Validation F1-Score: 0.4328 +/- 0.0303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "X = fast_graph_df.drop(['Status', 'SpecID'], axis=1)\n",
    "y = fast_graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et, svc]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores['test_accuracy']):.4f} +/- {np.std(scores['test_accuracy']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Precision: {np.mean(scores['test_precision_macro']):.4f} +/- {np.std(scores['test_precision_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Recall: {np.mean(scores['test_recall_macro']):.4f} +/- {np.std(scores['test_recall_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation F1-Score: {np.mean(scores['test_f1_macro']):.4f} +/- {np.std(scores['test_f1_macro']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_graph_df['SurID'] = fast_graph_df['SpecID'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Cross-Validation Accuracy: 0.4443 +/- 0.0837\n",
      "RandomForestClassifier Cross-Validation Precision: 0.4455 +/- 0.0800\n",
      "RandomForestClassifier Cross-Validation Recall: 0.4560 +/- 0.1111\n",
      "RandomForestClassifier Cross-Validation F1-Score: 0.4309 +/- 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.4403 +/- 0.0876\n",
      "ExtraTreesClassifier Cross-Validation Precision: 0.4411 +/- 0.0893\n",
      "ExtraTreesClassifier Cross-Validation Recall: 0.4510 +/- 0.1147\n",
      "ExtraTreesClassifier Cross-Validation F1-Score: 0.4257 +/- 0.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/stang/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Cross-Validation Accuracy: 0.3822 +/- 0.1509\n",
      "SVC Cross-Validation Precision: 0.4074 +/- 0.1812\n",
      "SVC Cross-Validation Recall: 0.3722 +/- 0.1731\n",
      "SVC Cross-Validation F1-Score: 0.3104 +/- 0.1327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "groups = fast_graph_df['SurID']\n",
    "X = fast_graph_df.drop(['Status', 'SpecID', 'SurID'], axis=1)\n",
    "y = fast_graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et, svc]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_validate(clf, X, y, groups=groups, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores['test_accuracy']):.4f} +/- {np.std(scores['test_accuracy']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Precision: {np.mean(scores['test_precision_macro']):.4f} +/- {np.std(scores['test_precision_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Recall: {np.mean(scores['test_recall_macro']):.4f} +/- {np.std(scores['test_recall_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation F1-Score: {np.mean(scores['test_f1_macro']):.4f} +/- {np.std(scores['test_f1_macro']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_graph_df['SurID'] = fast_graph_df['SpecID'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_120</th>\n",
       "      <th>embedding_121</th>\n",
       "      <th>embedding_122</th>\n",
       "      <th>embedding_123</th>\n",
       "      <th>embedding_124</th>\n",
       "      <th>embedding_125</th>\n",
       "      <th>embedding_126</th>\n",
       "      <th>embedding_127</th>\n",
       "      <th>Status</th>\n",
       "      <th>SurID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>-0.126856</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.312416</td>\n",
       "      <td>0.223328</td>\n",
       "      <td>0.128330</td>\n",
       "      <td>-0.112877</td>\n",
       "      <td>0.034097</td>\n",
       "      <td>-0.075095</td>\n",
       "      <td>0.027202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104161</td>\n",
       "      <td>0.107659</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>-0.055208</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>-0.101856</td>\n",
       "      <td>-0.005557</td>\n",
       "      <td>-0.018172</td>\n",
       "      <td>Normal</td>\n",
       "      <td>201210-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-01</td>\n",
       "      <td>-0.125399</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.311529</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>-0.112619</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>-0.076966</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102161</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.305113</td>\n",
       "      <td>-0.055215</td>\n",
       "      <td>0.042228</td>\n",
       "      <td>-0.103425</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>Normal</td>\n",
       "      <td>201210-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-02</td>\n",
       "      <td>-0.123358</td>\n",
       "      <td>0.039899</td>\n",
       "      <td>0.310530</td>\n",
       "      <td>0.217500</td>\n",
       "      <td>0.129119</td>\n",
       "      <td>-0.112073</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>-0.079315</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099716</td>\n",
       "      <td>0.110159</td>\n",
       "      <td>0.305353</td>\n",
       "      <td>-0.055236</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>-0.105426</td>\n",
       "      <td>-0.003343</td>\n",
       "      <td>-0.020210</td>\n",
       "      <td>Normal</td>\n",
       "      <td>201210-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-03</td>\n",
       "      <td>-0.110808</td>\n",
       "      <td>0.030174</td>\n",
       "      <td>0.303462</td>\n",
       "      <td>0.195779</td>\n",
       "      <td>0.132131</td>\n",
       "      <td>-0.110179</td>\n",
       "      <td>0.033030</td>\n",
       "      <td>-0.095497</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084771</td>\n",
       "      <td>0.119222</td>\n",
       "      <td>0.307137</td>\n",
       "      <td>-0.058461</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>-0.119889</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>-0.026324</td>\n",
       "      <td>Normal</td>\n",
       "      <td>201210-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-04</td>\n",
       "      <td>-0.121557</td>\n",
       "      <td>0.038382</td>\n",
       "      <td>0.309043</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.129492</td>\n",
       "      <td>-0.112088</td>\n",
       "      <td>0.034283</td>\n",
       "      <td>-0.082122</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097029</td>\n",
       "      <td>0.111685</td>\n",
       "      <td>0.306225</td>\n",
       "      <td>-0.055691</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>-0.107878</td>\n",
       "      <td>-0.002353</td>\n",
       "      <td>-0.021484</td>\n",
       "      <td>Normal</td>\n",
       "      <td>201210-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>210526-3-45</td>\n",
       "      <td>-0.127237</td>\n",
       "      <td>0.041604</td>\n",
       "      <td>0.312535</td>\n",
       "      <td>0.223764</td>\n",
       "      <td>0.128329</td>\n",
       "      <td>-0.113017</td>\n",
       "      <td>0.034144</td>\n",
       "      <td>-0.074790</td>\n",
       "      <td>0.027008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104495</td>\n",
       "      <td>0.107413</td>\n",
       "      <td>0.304829</td>\n",
       "      <td>-0.055150</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>-0.101533</td>\n",
       "      <td>-0.005722</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>210526-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>210526-3-46</td>\n",
       "      <td>-0.127292</td>\n",
       "      <td>0.041628</td>\n",
       "      <td>0.312574</td>\n",
       "      <td>0.223859</td>\n",
       "      <td>0.128286</td>\n",
       "      <td>-0.113043</td>\n",
       "      <td>0.034124</td>\n",
       "      <td>-0.074720</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104575</td>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.304797</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>0.043247</td>\n",
       "      <td>-0.101500</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>210526-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>210526-3-47</td>\n",
       "      <td>-0.127523</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.312714</td>\n",
       "      <td>0.224251</td>\n",
       "      <td>0.128193</td>\n",
       "      <td>-0.113105</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>-0.074430</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104905</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>0.304710</td>\n",
       "      <td>-0.055229</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>-0.101289</td>\n",
       "      <td>-0.005944</td>\n",
       "      <td>-0.017803</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>210526-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>210526-3-48</td>\n",
       "      <td>-0.127487</td>\n",
       "      <td>0.041724</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.224208</td>\n",
       "      <td>0.128208</td>\n",
       "      <td>-0.113091</td>\n",
       "      <td>0.034084</td>\n",
       "      <td>-0.074463</td>\n",
       "      <td>0.026809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104866</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>0.304716</td>\n",
       "      <td>-0.055224</td>\n",
       "      <td>0.043368</td>\n",
       "      <td>-0.101308</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.017824</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>210526-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>210526-3-49</td>\n",
       "      <td>-0.127388</td>\n",
       "      <td>0.041673</td>\n",
       "      <td>0.312632</td>\n",
       "      <td>0.224028</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>-0.113064</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074593</td>\n",
       "      <td>0.026890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104720</td>\n",
       "      <td>0.107328</td>\n",
       "      <td>0.304756</td>\n",
       "      <td>-0.055210</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>-0.101408</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>-0.017905</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>210526-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3045 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SpecID  embedding_0  embedding_1  embedding_2  embedding_3  \\\n",
       "0     201210-1-00    -0.126856     0.041533     0.312416     0.223328   \n",
       "1     201210-1-01    -0.125399     0.040796     0.311529     0.220783   \n",
       "2     201210-1-02    -0.123358     0.039899     0.310530     0.217500   \n",
       "3     201210-1-03    -0.110808     0.030174     0.303462     0.195779   \n",
       "4     201210-1-04    -0.121557     0.038382     0.309043     0.213698   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3040  210526-3-45    -0.127237     0.041604     0.312535     0.223764   \n",
       "3041  210526-3-46    -0.127292     0.041628     0.312574     0.223859   \n",
       "3042  210526-3-47    -0.127523     0.041741     0.312714     0.224251   \n",
       "3043  210526-3-48    -0.127487     0.041724     0.312700     0.224208   \n",
       "3044  210526-3-49    -0.127388     0.041673     0.312632     0.224028   \n",
       "\n",
       "      embedding_4  embedding_5  embedding_6  embedding_7  embedding_8  ...  \\\n",
       "0        0.128330    -0.112877     0.034097    -0.075095     0.027202  ...   \n",
       "1        0.128676    -0.112619     0.034209    -0.076966     0.028316  ...   \n",
       "2        0.129119    -0.112073     0.034152    -0.079315     0.029759  ...   \n",
       "3        0.132131    -0.110179     0.033030    -0.095497     0.039937  ...   \n",
       "4        0.129492    -0.112088     0.034283    -0.082122     0.031278  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "3040     0.128329    -0.113017     0.034144    -0.074790     0.027008  ...   \n",
       "3041     0.128286    -0.113043     0.034124    -0.074720     0.026967  ...   \n",
       "3042     0.128193    -0.113105     0.034084    -0.074430     0.026786  ...   \n",
       "3043     0.128208    -0.113091     0.034084    -0.074463     0.026809  ...   \n",
       "3044     0.128242    -0.113064     0.034098    -0.074593     0.026890  ...   \n",
       "\n",
       "      embedding_120  embedding_121  embedding_122  embedding_123  \\\n",
       "0         -0.104161       0.107659       0.304749      -0.055208   \n",
       "1         -0.102161       0.108725       0.305113      -0.055215   \n",
       "2         -0.099716       0.110159       0.305353      -0.055236   \n",
       "3         -0.084771       0.119222       0.307137      -0.058461   \n",
       "4         -0.097029       0.111685       0.306225      -0.055691   \n",
       "...             ...            ...            ...            ...   \n",
       "3040      -0.104495       0.107413       0.304829      -0.055150   \n",
       "3041      -0.104575       0.107379       0.304797      -0.055179   \n",
       "3042      -0.104905       0.107231       0.304710      -0.055229   \n",
       "3043      -0.104866       0.107252       0.304716      -0.055224   \n",
       "3044      -0.104720       0.107328       0.304756      -0.055210   \n",
       "\n",
       "      embedding_124  embedding_125  embedding_126  embedding_127  \\\n",
       "0          0.043022      -0.101856      -0.005557      -0.018172   \n",
       "1          0.042228      -0.103425      -0.004603      -0.019147   \n",
       "2          0.041107      -0.105426      -0.003343      -0.020210   \n",
       "3          0.033479      -0.119889       0.002414      -0.026324   \n",
       "4          0.040199      -0.107878      -0.002353      -0.021484   \n",
       "...             ...            ...            ...            ...   \n",
       "3040       0.043200      -0.101533      -0.005722      -0.018050   \n",
       "3041       0.043247      -0.101500      -0.005773      -0.017992   \n",
       "3042       0.043399      -0.101289      -0.005944      -0.017803   \n",
       "3043       0.043368      -0.101308      -0.005926      -0.017824   \n",
       "3044       0.043305      -0.101408      -0.005841      -0.017905   \n",
       "\n",
       "             Status     SurID  \n",
       "0            Normal  201210-1  \n",
       "1            Normal  201210-1  \n",
       "2            Normal  201210-1  \n",
       "3            Normal  201210-1  \n",
       "4            Normal  201210-1  \n",
       "...             ...       ...  \n",
       "3040  Hyperglycemia  210526-3  \n",
       "3041  Hyperglycemia  210526-3  \n",
       "3042  Hyperglycemia  210526-3  \n",
       "3043  Hyperglycemia  210526-3  \n",
       "3044  Hyperglycemia  210526-3  \n",
       "\n",
       "[3045 rows x 131 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1423\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m cv \u001b[38;5;241m=\u001b[39m GroupKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Getting cross-validation scores\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Displaying the results\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cross-Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1950\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(output)\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m-> 1950\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1588\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1586\u001b[0m detach_generator_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1571\u001b[0m, in \u001b[0;36mParallel._start\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1434\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1431\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m   1432\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[0;32m-> 1434\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:377\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         (\n\u001b[1;32m    372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    375\u001b[0m     )\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:108\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    107\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m    109\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m    110\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:120\u001b[0m, in \u001b[0;36mBaseCrossValidator._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates boolean masks corresponding to test sets.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    By default, delegates to _iter_test_indices(X, y, groups)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_indices(X, y, groups):\n\u001b[1;32m    121\u001b[0m         test_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(_num_samples(X), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    122\u001b[0m         test_mask[test_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:564\u001b[0m, in \u001b[0;36mGroupKFold._iter_test_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter should not be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 564\u001b[0m groups \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroups\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m unique_groups, groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(groups, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    567\u001b[0m n_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(unique_groups)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:111\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(X\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "# Splitting the dataframe into features (X) and target variable (y)\n",
    "groups = fast_graph_df['SurID']\n",
    "X = fast_graph_df.drop(['Status', 'SpecID'], axis=1)\n",
    "y = fast_graph_df['Status']\n",
    "\n",
    "# Creating the classifiers\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Combining the classifiers into a list\n",
    "classifiers = [rf, et, svc]\n",
    "\n",
    "# Performing 10-fold cross-validation for each classifier\n",
    "for clf in classifiers:\n",
    "    \n",
    "    # Using StratifiedKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_validate(clf, X, y, groups=groups, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores['test_accuracy']):.4f} +/- {np.std(scores['test_accuracy']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Precision: {np.mean(scores['test_precision_macro']):.4f} +/- {np.std(scores['test_precision_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation Recall: {np.mean(scores['test_recall_macro']):.4f} +/- {np.std(scores['test_recall_macro']):.4f}\")\n",
    "    print(f\"{clf.__class__.__name__} Cross-Validation F1-Score: {np.mean(scores['test_f1_macro']):.4f} +/- {np.std(scores['test_f1_macro']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast rp mixed with traditional graph metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_graph = pd.merge(graph_df, fast_graph_df, on=['SpecID', 'Status'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7142857142857143\n",
      "Extra Trees Accuracy: 0.6962233169129721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Drop the SpecID column\n",
    "X = joined_graph.drop(columns=['SpecID', 'Status'])\n",
    "\n",
    "# Target variable\n",
    "y = joined_graph['Status']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1234)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Extra Trees model\n",
    "et_model = ExtraTreesClassifier(n_estimators=100, random_state=1234)\n",
    "et_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "et_predictions = et_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "et_accuracy = accuracy_score(y_test, et_predictions)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Extra Trees Accuracy:\", et_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_projection(tx):\n",
    "    query = \"\"\"\n",
    "    CALL gds.graph.drop('myGraph')\n",
    "    \"\"\"\n",
    "    tx.run(query)\n",
    "\n",
    "# Use a session to execute the graph projection\n",
    "with driver.session() as session:\n",
    "    session.execute_write(delete_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
