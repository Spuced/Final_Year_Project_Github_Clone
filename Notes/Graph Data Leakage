In theory, data leakage is not an issue, as new unlabelled samples could be added to a graph with the full dataset.

To demonstrate how the model varies with different graph constructions we could use nested cross validation, creating graphs from each 90% subset of the dataset.

I think we do his way with testing and training graphs.

Then we test different 90% folds

Graph ideas.

Nodes are samples, then connect the nodes to other nodes with peaks in the same grid slot.
