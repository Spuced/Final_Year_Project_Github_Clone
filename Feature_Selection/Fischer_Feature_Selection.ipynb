{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, cross_val_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../data/exosomes.raw_spectrum_1.csv\")\n",
    "#df = pd.read_csv(\"../data/exosomes.raw_spectrum_380-1800.csv\")\n",
    "#df = pd.read_csv(\"../data/exosomes.raw_spectrum_400-1800.csv\")\n",
    "df = pd.read_csv(\"../data/current_clean_spectrum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>WaveNumber</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Absorbance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>293</td>\n",
       "      <td>400.22778</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.863303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>294</td>\n",
       "      <td>400.91116</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.803843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>295</td>\n",
       "      <td>401.59454</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.741884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>296</td>\n",
       "      <td>402.27789</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.677722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201210-1-00</td>\n",
       "      <td>297</td>\n",
       "      <td>402.96127</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>41.611654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239200</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2337</td>\n",
       "      <td>1797.03870</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>12.378163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239201</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2338</td>\n",
       "      <td>1797.72200</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>13.269937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239202</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2339</td>\n",
       "      <td>1798.40550</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>14.199285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239203</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2340</td>\n",
       "      <td>1799.08890</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>15.166531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239204</th>\n",
       "      <td>210526-3-09</td>\n",
       "      <td>2341</td>\n",
       "      <td>1799.77220</td>\n",
       "      <td>210526-3</td>\n",
       "      <td>Hyperglycemia</td>\n",
       "      <td>16.171997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6239205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SpecID   Seq  WaveNumber     SurID         Status  Absorbance\n",
       "0        201210-1-00   293   400.22778  201210-1         Normal   41.863303\n",
       "1        201210-1-00   294   400.91116  201210-1         Normal   41.803843\n",
       "2        201210-1-00   295   401.59454  201210-1         Normal   41.741884\n",
       "3        201210-1-00   296   402.27789  201210-1         Normal   41.677722\n",
       "4        201210-1-00   297   402.96127  201210-1         Normal   41.611654\n",
       "...              ...   ...         ...       ...            ...         ...\n",
       "6239200  210526-3-09  2337  1797.03870  210526-3  Hyperglycemia   12.378163\n",
       "6239201  210526-3-09  2338  1797.72200  210526-3  Hyperglycemia   13.269937\n",
       "6239202  210526-3-09  2339  1798.40550  210526-3  Hyperglycemia   14.199285\n",
       "6239203  210526-3-09  2340  1799.08890  210526-3  Hyperglycemia   15.166531\n",
       "6239204  210526-3-09  2341  1799.77220  210526-3  Hyperglycemia   16.171997\n",
       "\n",
       "[6239205 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_wavelength_df(df, absorbance_col, status_col='Status'):\n",
    "\n",
    "    # Pivot the DataFrame to get wavelengths as columns and absorbance values\n",
    "    wavelength_df = df.pivot(index='SpecID', columns='WaveNumber', values=absorbance_col).reset_index()\n",
    "    wavelength_df.columns.name = None\n",
    "\n",
    "    # Merge with the statuses based on SpecID\n",
    "    # Include the SurID to perform GroupKFold CV\n",
    "    statuses_and_surface = df[['SpecID', 'SurID', status_col]].drop_duplicates()\n",
    "    wavelength_df = pd.merge(wavelength_df, statuses_and_surface, on='SpecID')\n",
    "\n",
    "    # Set SpecID as the index\n",
    "    wavelength_df = wavelength_df.set_index('SpecID')\n",
    "\n",
    "    return wavelength_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees(df):\n",
    "\n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy',groups=groups)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_df = prepare_wavelength_df(df, 'Absorbance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>400.22778</th>\n",
       "      <th>400.91116</th>\n",
       "      <th>401.59454</th>\n",
       "      <th>402.27789</th>\n",
       "      <th>402.96127</th>\n",
       "      <th>403.64465</th>\n",
       "      <th>404.32803</th>\n",
       "      <th>405.01138</th>\n",
       "      <th>405.69476</th>\n",
       "      <th>406.37814</th>\n",
       "      <th>...</th>\n",
       "      <th>1794.9886</th>\n",
       "      <th>1795.672</th>\n",
       "      <th>1796.3553</th>\n",
       "      <th>1797.0387</th>\n",
       "      <th>1797.722</th>\n",
       "      <th>1798.4055</th>\n",
       "      <th>1799.0889</th>\n",
       "      <th>1799.7722</th>\n",
       "      <th>SurID</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201210-1-00</th>\n",
       "      <td>41.863303</td>\n",
       "      <td>41.803843</td>\n",
       "      <td>41.741884</td>\n",
       "      <td>41.677722</td>\n",
       "      <td>41.611654</td>\n",
       "      <td>41.543974</td>\n",
       "      <td>41.474980</td>\n",
       "      <td>41.404968</td>\n",
       "      <td>41.334234</td>\n",
       "      <td>41.263073</td>\n",
       "      <td>...</td>\n",
       "      <td>6.280946</td>\n",
       "      <td>5.549559</td>\n",
       "      <td>4.745724</td>\n",
       "      <td>3.866578</td>\n",
       "      <td>2.909255</td>\n",
       "      <td>1.870891</td>\n",
       "      <td>0.748623</td>\n",
       "      <td>-0.460415</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-01</th>\n",
       "      <td>46.314608</td>\n",
       "      <td>47.323684</td>\n",
       "      <td>48.299209</td>\n",
       "      <td>49.241395</td>\n",
       "      <td>50.150457</td>\n",
       "      <td>51.026608</td>\n",
       "      <td>51.870063</td>\n",
       "      <td>52.681035</td>\n",
       "      <td>53.459738</td>\n",
       "      <td>54.206386</td>\n",
       "      <td>...</td>\n",
       "      <td>6.769011</td>\n",
       "      <td>7.280928</td>\n",
       "      <td>7.861246</td>\n",
       "      <td>8.512936</td>\n",
       "      <td>9.238972</td>\n",
       "      <td>10.042323</td>\n",
       "      <td>10.925962</td>\n",
       "      <td>11.892860</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-02</th>\n",
       "      <td>118.159018</td>\n",
       "      <td>114.686240</td>\n",
       "      <td>111.563911</td>\n",
       "      <td>108.777452</td>\n",
       "      <td>106.312282</td>\n",
       "      <td>104.153823</td>\n",
       "      <td>102.287493</td>\n",
       "      <td>100.698715</td>\n",
       "      <td>99.372907</td>\n",
       "      <td>98.295491</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.633601</td>\n",
       "      <td>-4.557349</td>\n",
       "      <td>-4.439365</td>\n",
       "      <td>-4.278894</td>\n",
       "      <td>-4.075180</td>\n",
       "      <td>-3.827470</td>\n",
       "      <td>-3.535010</td>\n",
       "      <td>-3.197043</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-03</th>\n",
       "      <td>175.466997</td>\n",
       "      <td>174.846086</td>\n",
       "      <td>174.188020</td>\n",
       "      <td>173.498226</td>\n",
       "      <td>172.782129</td>\n",
       "      <td>172.045155</td>\n",
       "      <td>171.292728</td>\n",
       "      <td>170.530275</td>\n",
       "      <td>169.763222</td>\n",
       "      <td>168.996993</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.801936</td>\n",
       "      <td>-10.349539</td>\n",
       "      <td>-9.864191</td>\n",
       "      <td>-9.347124</td>\n",
       "      <td>-8.799567</td>\n",
       "      <td>-8.222752</td>\n",
       "      <td>-7.617909</td>\n",
       "      <td>-6.986269</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201210-1-04</th>\n",
       "      <td>111.814973</td>\n",
       "      <td>106.629998</td>\n",
       "      <td>101.867380</td>\n",
       "      <td>97.512673</td>\n",
       "      <td>93.551430</td>\n",
       "      <td>89.969205</td>\n",
       "      <td>86.751551</td>\n",
       "      <td>83.884023</td>\n",
       "      <td>81.352173</td>\n",
       "      <td>79.141556</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.689508</td>\n",
       "      <td>-11.752441</td>\n",
       "      <td>-11.789205</td>\n",
       "      <td>-11.799583</td>\n",
       "      <td>-11.783357</td>\n",
       "      <td>-11.740310</td>\n",
       "      <td>-11.670224</td>\n",
       "      <td>-11.572882</td>\n",
       "      <td>201210-1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              400.22778   400.91116   401.59454   402.27789   402.96127  \\\n",
       "SpecID                                                                    \n",
       "201210-1-00   41.863303   41.803843   41.741884   41.677722   41.611654   \n",
       "201210-1-01   46.314608   47.323684   48.299209   49.241395   50.150457   \n",
       "201210-1-02  118.159018  114.686240  111.563911  108.777452  106.312282   \n",
       "201210-1-03  175.466997  174.846086  174.188020  173.498226  172.782129   \n",
       "201210-1-04  111.814973  106.629998  101.867380   97.512673   93.551430   \n",
       "\n",
       "              403.64465   404.32803   405.01138   405.69476   406.37814  ...  \\\n",
       "SpecID                                                                   ...   \n",
       "201210-1-00   41.543974   41.474980   41.404968   41.334234   41.263073  ...   \n",
       "201210-1-01   51.026608   51.870063   52.681035   53.459738   54.206386  ...   \n",
       "201210-1-02  104.153823  102.287493  100.698715   99.372907   98.295491  ...   \n",
       "201210-1-03  172.045155  171.292728  170.530275  169.763222  168.996993  ...   \n",
       "201210-1-04   89.969205   86.751551   83.884023   81.352173   79.141556  ...   \n",
       "\n",
       "             1794.9886   1795.672  1796.3553  1797.0387   1797.722  1798.4055  \\\n",
       "SpecID                                                                          \n",
       "201210-1-00   6.280946   5.549559   4.745724   3.866578   2.909255   1.870891   \n",
       "201210-1-01   6.769011   7.280928   7.861246   8.512936   9.238972  10.042323   \n",
       "201210-1-02  -4.633601  -4.557349  -4.439365  -4.278894  -4.075180  -3.827470   \n",
       "201210-1-03 -10.801936 -10.349539  -9.864191  -9.347124  -8.799567  -8.222752   \n",
       "201210-1-04 -11.689508 -11.752441 -11.789205 -11.799583 -11.783357 -11.740310   \n",
       "\n",
       "             1799.0889  1799.7722     SurID  Status  \n",
       "SpecID                                               \n",
       "201210-1-00   0.748623  -0.460415  201210-1  Normal  \n",
       "201210-1-01  10.925962  11.892860  201210-1  Normal  \n",
       "201210-1-02  -3.535010  -3.197043  201210-1  Normal  \n",
       "201210-1-03  -7.617909  -6.986269  201210-1  Normal  \n",
       "201210-1-04 -11.670224 -11.572882  201210-1  Normal  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelength_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees(df):\n",
    "\n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X, y, cv=cv, scoring='accuracy',groups=groups, n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.6123 +/- 0.1083\n"
     ]
    }
   ],
   "source": [
    "evaluate_extra_trees(wavelength_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fisher Score Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_trees_with_fisher_score(df, num_features):\n",
    "    \n",
    "    # Set the Surfaces as groups\n",
    "    groups = df['SurID']\n",
    "    X = df.drop(['Status', 'SurID'], axis=1)\n",
    "    y = df['Status']\n",
    "\n",
    "    # Feature Selection with Fisher Score\n",
    "    selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Creating the Extra Trees classifier\n",
    "    et = ExtraTreesClassifier(random_state=1234)\n",
    "    \n",
    "    # Using GroupKFold for classification tasks\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    \n",
    "    # Getting cross-validation scores\n",
    "    scores = cross_val_score(et, X_selected, y, cv=cv, scoring='accuracy', groups=groups, n_jobs=-1)\n",
    "    \n",
    "    # Displaying the results\n",
    "    print(f'{et.__class__.__name__} Cross-Validation Accuracy: {np.mean(scores):.4f} +/- {np.std(scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier Cross-Validation Accuracy: 0.4748 +/- 0.0860\n"
     ]
    }
   ],
   "source": [
    "evaluate_extra_trees_with_fisher_score(wavelength_df, num_features=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Permutation Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the groups for surfaces\n",
    "groups = wavelength_df['SurID']\n",
    "X = wavelength_df.drop(['Status', 'SurID'], axis=1)\n",
    "y = wavelength_df['Status']\n",
    "\n",
    "# Creating the Extra Trees classifier\n",
    "et = ExtraTreesClassifier(random_state=1234)\n",
    "\n",
    "# Fitting the model on the entire dataset\n",
    "et.fit(X, y)\n",
    "\n",
    "# Calculating permutation importance\n",
    "result = permutation_importance(et, X, y, n_repeats=1, random_state=1234, n_jobs=-1)\n",
    "\n",
    "# Creating a DataFrame for feature importance\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance Mean': result.importances_mean,\n",
    "    'Importance Std Dev': result.importances_std\n",
    "})\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(\"\\nFeature importance:\")\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function permutation_importance in module sklearn.inspection._permutation_importance:\n",
      "\n",
      "permutation_importance(estimator, X, y, *, scoring=None, n_repeats=5, n_jobs=None, random_state=None, sample_weight=None, max_samples=1.0)\n",
      "    Permutation importance for feature evaluation [BRE]_.\n",
      "    \n",
      "    The :term:`estimator` is required to be a fitted estimator. `X` can be the\n",
      "    data set used to train the estimator or a hold-out set. The permutation\n",
      "    importance of a feature is calculated as follows. First, a baseline metric,\n",
      "    defined by :term:`scoring`, is evaluated on a (potentially different)\n",
      "    dataset defined by the `X`. Next, a feature column from the validation set\n",
      "    is permuted and the metric is evaluated again. The permutation importance\n",
      "    is defined to be the difference between the baseline metric and metric from\n",
      "    permutating the feature column.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <permutation_importance>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : object\n",
      "        An estimator that has already been :term:`fitted` and is compatible\n",
      "        with :term:`scorer`.\n",
      "    \n",
      "    X : ndarray or DataFrame, shape (n_samples, n_features)\n",
      "        Data on which permutation importance will be computed.\n",
      "    \n",
      "    y : array-like or None, shape (n_samples, ) or (n_samples, n_classes)\n",
      "        Targets for supervised or `None` for unsupervised.\n",
      "    \n",
      "    scoring : str, callable, list, tuple, or dict, default=None\n",
      "        Scorer to use.\n",
      "        If `scoring` represents a single score, one can use:\n",
      "    \n",
      "        - a single string (see :ref:`scoring_parameter`);\n",
      "        - a callable (see :ref:`scoring`) that returns a single value.\n",
      "    \n",
      "        If `scoring` represents multiple scores, one can use:\n",
      "    \n",
      "        - a list or tuple of unique strings;\n",
      "        - a callable returning a dictionary where the keys are the metric\n",
      "          names and the values are the metric scores;\n",
      "        - a dictionary with metric names as keys and callables a values.\n",
      "    \n",
      "        Passing multiple scores to `scoring` is more efficient than calling\n",
      "        `permutation_importance` for each of the scores as it reuses\n",
      "        predictions to avoid redundant computation.\n",
      "    \n",
      "        If None, the estimator's default scorer is used.\n",
      "    \n",
      "    n_repeats : int, default=5\n",
      "        Number of times to permute a feature.\n",
      "    \n",
      "    n_jobs : int or None, default=None\n",
      "        Number of jobs to run in parallel. The computation is done by computing\n",
      "        permutation score for each columns and parallelized over the columns.\n",
      "        `None` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        `-1` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    random_state : int, RandomState instance, default=None\n",
      "        Pseudo-random number generator to control the permutations of each\n",
      "        feature.\n",
      "        Pass an int to get reproducible results across function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights used in scoring.\n",
      "    \n",
      "        .. versionadded:: 0.24\n",
      "    \n",
      "    max_samples : int or float, default=1.0\n",
      "        The number of samples to draw from X to compute feature importance\n",
      "        in each repeat (without replacement).\n",
      "    \n",
      "        - If int, then draw `max_samples` samples.\n",
      "        - If float, then draw `max_samples * X.shape[0]` samples.\n",
      "        - If `max_samples` is equal to `1.0` or `X.shape[0]`, all samples\n",
      "          will be used.\n",
      "    \n",
      "        While using this option may provide less accurate importance estimates,\n",
      "        it keeps the method tractable when evaluating feature importance on\n",
      "        large datasets. In combination with `n_repeats`, this allows to control\n",
      "        the computational speed vs statistical accuracy trade-off of this method.\n",
      "    \n",
      "        .. versionadded:: 1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : :class:`~sklearn.utils.Bunch` or dict of such instances\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        importances_mean : ndarray of shape (n_features, )\n",
      "            Mean of feature importance over `n_repeats`.\n",
      "        importances_std : ndarray of shape (n_features, )\n",
      "            Standard deviation over `n_repeats`.\n",
      "        importances : ndarray of shape (n_features, n_repeats)\n",
      "            Raw permutation importance scores.\n",
      "    \n",
      "        If there are multiple scoring metrics in the scoring parameter\n",
      "        `result` is a dict with scorer names as keys (e.g. 'roc_auc') and\n",
      "        `Bunch` objects like above as values.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [BRE] :doi:`L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32,\n",
      "             2001. <10.1023/A:1010933404324>`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.linear_model import LogisticRegression\n",
      "    >>> from sklearn.inspection import permutation_importance\n",
      "    >>> X = [[1, 9, 9],[1, 9, 9],[1, 9, 9],\n",
      "    ...      [0, 9, 9],[0, 9, 9],[0, 9, 9]]\n",
      "    >>> y = [1, 1, 1, 0, 0, 0]\n",
      "    >>> clf = LogisticRegression().fit(X, y)\n",
      "    >>> result = permutation_importance(clf, X, y, n_repeats=10,\n",
      "    ...                                 random_state=0)\n",
      "    >>> result.importances_mean\n",
      "    array([0.4666..., 0.       , 0.       ])\n",
      "    >>> result.importances_std\n",
      "    array([0.2211..., 0.       , 0.       ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(permutation_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
